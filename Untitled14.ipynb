{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOr6M90VGdiThY3Rn+ttXuK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naik134234/DASH/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: numpy>=1.21.0\n",
        "# pandas>=1.3.0\n",
        "# yfinance>=0.1.63\n",
        "# matplotlib>=3.4.0\n",
        "# scikit-learn>=0.24.0\n",
        "# tensorflow>=2.6.0\n",
        "# ta>=0.7.0\n",
        "# streamlit>=1.0.0\n",
        "# schedule>=1.1.0\n",
        "# openpyxl>=3.0.7\n",
        "# xlsxwriter>=3.0.1\n",
        "# python-telegram-bot>=13.7\n",
        "# requests>=2.26.0\n",
        "# plotly>=5.3.0\n",
        "# pytrends>=4.8.0\n",
        "# SQLAlchemy>=1.4.0\n",
        "# beautifulsoup4>=4.10.0\n",
        "# kaleido>=0.2.1\n",
        "# statsmodels>=0.13.0\n",
        "# scipy>=1.7.0\n",
        "# python-dotenv>=0.19.0\n",
        "# pyportfolioopt>=1.4.0\n",
        "# newsapi-python>=0.2.6\n",
        "\n",
        "!pip install numpy>=1.21.0 pandas>=1.3.0 yfinance>=0.1.63 matplotlib>=3.4.0 scikit-learn>=0.24.0 tensorflow>=2.6.0 ta>=0.7.0 streamlit>=1.0.0 schedule>=1.1.0 openpyxl>=3.0.7 xlsxwriter>=3.0.1 python-telegram-bot>=13.7 requests>=2.26.0 plotly>=5.3.0 pytrends>=4.8.0 SQLAlchemy>=1.4.0 beautifulsoup4>=4.10.0 kaleido>=0.2.1 statsmodels>=0.13.0 scipy>=1.7.0 python-dotenv>=0.19.0 pyportfolioopt>=1.4.0 newsapi-python>=0.2.6\n"
      ],
      "metadata": {
        "id": "n4Cnto-2SO6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import numpy as np\n",
        "# import pandas as pd\n",
        "# import yfinance as yf\n",
        "# from datetime import datetime, timedelta\n",
        "# import ta\n",
        "# from scipy import stats\n",
        "# import sqlite3\n",
        "# import matplotlib.pyplot as plt\n",
        "# import plotly.express as px\n",
        "# import plotly.graph_objects as go\n",
        "# class Nifty50RiskModel:\n",
        "#     def __init__(self):\n",
        "#         self.nifty50_tickers = [\n",
        "#             \"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\",\n",
        "#             \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"LT.NS\"\n",
        "#         ]\n",
        "#         self.alpha = 0.05  # 95% confidence level\n",
        "#         self.db_path = \"risk_alerts.db\"\n",
        "#         self.setup_database()\n",
        "#     def setup_database(self):\n",
        "#         \"\"\"Setup SQLite database for storing alerts\"\"\"\n",
        "#         conn = sqlite3.connect(self.db_path)\n",
        "#         cursor = conn.cursor()\n",
        "#         cursor.execute(\"\"\"\n",
        "#         CREATE TABLE IF NOT EXISTS alerts (\n",
        "#             id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "#             timestamp TEXT,\n",
        "#             alert_type TEXT,\n",
        "#             value REAL,\n",
        "#             message TEXT\n",
        "#         )\n",
        "#         \"\"\")\n",
        "#         cursor.execute(\"\"\"\n",
        "#         CREATE TABLE IF NOT EXISTS risk_metrics (\n",
        "#             id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "#             timestamp TEXT,\n",
        "#             var_historical REAL,\n",
        "#             var_parametric REAL,\n",
        "#             var_monte_carlo REAL,\n",
        "#             cvar REAL,\n",
        "#             mdd REAL,\n",
        "#             omega_ratio REAL,\n",
        "#             entropic_var REAL,\n",
        "#             tail_risk REAL,\n",
        "#             skewness REAL,\n",
        "#             kurtosis REAL\n",
        "#         )\n",
        "#         \"\"\")\n",
        "#         conn.commit()\n",
        "#         conn.close()\n",
        "#     def fetch_data(self, start_date=None, end_date=None):\n",
        "#         \"\"\"Fetch historical stock data\"\"\"\n",
        "#         if start_date is None:\n",
        "#             start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "#         if end_date is None:\n",
        "#             end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "#         data = yf.download(self.nifty50_tickers, start=start_date, end=end_date)['Adj Close']\n",
        "#         return data\n",
        "#     def calculate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import ta\n",
        "from scipy import stats\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "class Nifty50RiskModel:\n",
        "    def __init__(self):\n",
        "        self.nifty50_tickers = [\n",
        "            \"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\",\n",
        "            \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"LT.NS\"\n",
        "        ]\n",
        "        self.alpha = 0.05  # 95% confidence level\n",
        "        self.db_path = \"risk_alerts.db\"\n",
        "        self.setup_database()\n",
        "    def setup_database(self):\n",
        "        \"\"\"Setup SQLite database for storing alerts\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS alerts (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            alert_type TEXT,\n",
        "            value REAL,\n",
        "            message TEXT\n",
        "        )\n",
        "        \"\"\")\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS risk_metrics (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            var_historical REAL,\n",
        "            var_parametric REAL,\n",
        "            var_monte_carlo REAL,\n",
        "            cvar REAL,\n",
        "            mdd REAL,\n",
        "            omega_ratio REAL,\n",
        "            entropic_var REAL,\n",
        "            tail_risk REAL,\n",
        "            skewness REAL,\n",
        "            kurtosis REAL\n",
        "        )\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    def fetch_data(self, start_date=None, end_date=None):\n",
        "        \"\"\"Fetch historical stock data\"\"\"\n",
        "        if start_date is None:\n",
        "            start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "        if end_date is None:\n",
        "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "        data = yf.download(self.nifty50_tickers, start=start_date, end=end_date)['Adj Close']\n",
        "        return data\n",
        "    def calculate_risk_metrics(self, data):\n",
        "        \"\"\"Calculate various risk metrics for the portfolio\"\"\"\n",
        "        returns = data.pct_change().dropna()\n",
        "        portfolio_returns = returns.mean(axis=1)\n",
        "        # Historical VaR\n",
        "        var_historical = np.percentile(portfolio_returns, self.alpha * 100)\n",
        "        # Parametric VaR (assuming normal distribution)\n",
        "        var_parametric = portfolio_returns.mean() + portfolio_returns.std() * stats.norm.ppf(self.alpha)\n",
        "        # Other risk metrics (e.g., CVaR, MDD, Omega Ratio, etc.) can be added here\n",
        "        # ...\n",
        "        risk_metrics = {\n",
        "            \"var_historical\": var_historical,\n",
        "            \"var_parametric\": var_parametric,\n",
        "            # Add other risk metrics\n",
        "        }\n",
        "        return risk_metrics\n",
        "    def store_risk_metrics(self, risk_metrics):\n",
        "        \"\"\"Store calculated risk metrics in the database\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            INSERT INTO risk_metrics (timestamp, var_historical, var_parametric)\n",
        "            VALUES (?, ?, ?)\n",
        "        \"\"\", (datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), risk_metrics[\"var_historical\"], risk_metrics[\"var_parametric\"]))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    def run(self):\n",
        "        \"\"\"Main function to fetch data, calculate risk, and generate alerts\"\"\"\n",
        "        data = self.fetch_data()\n",
        "        risk_metrics = self.calculate_risk_metrics(data)\n",
        "        self.store_risk_metrics(risk_metrics)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    risk_model = Nifty50RiskModel()\n",
        "    risk_model.run()\n",
        "\n"
      ],
      "metadata": {
        "id": "MzZDRedYSaY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import numpy as np\n",
        "# import pandas as pd\n",
        "# from scipy.optimize import minimize\n",
        "# from risk_model import Nifty50RiskModel\n",
        "# class PortfolioOptimizer:\n",
        "#     def __init__(self, risk_model):\n",
        "#         self.risk_model = risk_model\n",
        "#     def mean_variance_optimization(self, returns, risk_free_rate=0.0, target_return=None):\n",
        "#         \"\"\"Traditional Markowitz Mean-Variance Optimization\"\"\"\n",
        "#         n = len(returns.columns)\n",
        "#         returns_mean = returns.mean()\n",
        "#         cov_matrix = returns.cov()\n",
        "#         # Define optimization objective: minimize portfolio variance\n",
        "#         def portfolio_variance(weights):\n",
        "#             return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
        "#         # Define constraints\n",
        "#         constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # weights sum to 1\n",
        "#         # Add target return constraint if specified\n",
        "#         if target_return is not None:\n",
        "#             constraints.append({\n",
        "#                 'type': 'eq',\n",
        "#                 'fun': lambda w: np.dot(w, returns_mean) - target_return\n",
        "#             })\n",
        "#         # Define bounds (no short selling)\n",
        "#         bounds = tuple((0, 1) for _ in range(n))\n",
        "#         # Initial guess\n",
        "#         initial_weights = np.ones(n) / n\n",
        "#         # Optimize\n",
        "#         result = minimize(\n",
        "#             portfolio_variance,\n",
        "#             initial_weights,\n",
        "#             method='SLSQP',\n",
        "#             bounds=bounds,\n",
        "#             constraints=constraints\n",
        "#         )\n",
        "#         # Calculate portfolio metrics\n",
        "#         weights = result['x']\n",
        "#         portfolio_return = np.dot(weights, returns_mean)\n",
        "#         portfolio_volatility = np.sqrt(portfolio_variance(weights))\n",
        "#         sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
        "#         return {\n",
        "#             'weights': dict(zip(returns.columns, weights)),\n",
        "#             'return': portfolio_return,\n",
        "#             'volatility': portfolio_volatility,\n",
        "#             'sharpe_ratio': sharpe_ratio\n",
        "#         }\n",
        "#     def mean_cvar_optimization(self, retu\n",
        "\n",
        "import numpy as np\n",
        "rns), risk_free_rate=0.0, target_return=None, alpha=0.05):\n",
        "        \"\"\"Mean-CVaR Optimization\"\"\"\n",
        "        n = len(returns.columns)\n",
        "        returns_mean = returns.mean()\n",
        "        cov_matrix = returns.cov()\n",
        "\n",
        "        # Define optimization objective: minimize CVaR\n",
        "        def portfolio_cvar(weights):\n",
        "            portfolio_returns = np.dot(returns, weights)\n",
        "            return -np.mean(portfolio_returns[portfolio_returns <= np.percentile(portfolio_returns, alpha * 100)])\n",
        "\n",
        "        # Define constraints\n",
        "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # weights sum to 1\n",
        "        # Add target return constraint if specified\n",
        "        if target_return is not None:\n",
        "            constraints.append({\n",
        "                'type': 'eq',\n",
        "                'fun': lambda w: np.dot(w, returns_mean) - target_return\n",
        "            })\n",
        "        # Define bounds (no short selling)\n",
        "        bounds = tuple((0, 1) for _ in range(n))\n",
        "\n",
        "        # Initial guess\n",
        "        initial_weights = np.ones(n) / n\n",
        "        # Optimize\n",
        "        result = minimize(\n",
        "            portfolio_cvar,\n",
        "            initial_weights,\n",
        "            method='SLSQP',\n",
        "            bounds=bounds,\n",
        "            constraints=constraints\n",
        "        )\n",
        "\n",
        "        # Calculate portfolio metrics\n",
        "        weights = result['x']\n",
        "        portfolio_return = np.dot(weights, returns_mean)\n",
        "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
        "        return {\n",
        "            'weights': dict(zip(returns.columns, weights)),\n",
        "            'return': portfolio_return,\n",
        "            'volatility': portfolio_volatility,\n",
        "            'sharpe_ratio': sharpe_ratio\n",
        "        }\n"
      ],
      "metadata": {
        "id": "or-5CC2RTdD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NIFTY 50 Risk Management System\n",
        "# Comprehensive risk modeling and portfolio optimization\n",
        "\n",
        "# Install required packages\n",
        "!pip install numpy pandas yfinance matplotlib scikit-learn tensorflow ta streamlit schedule openpyxl xlsxwriter python-telegram-bot requests plotly pytrends beautifulsoup4 kaleido statsmodels scipy python-dotenv pyportfolioopt newsapi-python"
      ],
      "metadata": {
        "id": "JF8BkDtXVFj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from scipy import stats\n",
        "import ta\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import warnings\n",
        "import requests\n",
        "import io\n",
        "import json\n",
        "import sqlite3\n",
        "import os\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create a Google Drive mount point for persistent storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for our project\n",
        "!mkdir -p \"/content/drive/MyDrive/NiftyRiskModel\"\n",
        "os.chdir(\"/content/drive/MyDrive/NiftyRiskModel\")"
      ],
      "metadata": {
        "id": "vFA9RcFMVGYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Nifty50RiskModel:\n",
        "    def __init__(self):\n",
        "        self.nifty50_tickers = [\n",
        "            \"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\",\n",
        "            \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"LT.NS\"\n",
        "        ]\n",
        "        self.alpha = 0.05  # 95% confidence level\n",
        "        self.db_path = \"risk_alerts.db\"\n",
        "        self.setup_database()\n",
        "\n",
        "    def setup_database(self):\n",
        "        \"\"\"Setup SQLite database for storing alerts\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS alerts (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            alert_type TEXT,\n",
        "            value REAL,\n",
        "            message TEXT\n",
        "        )\n",
        "        \"\"\")\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS risk_metrics (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            timestamp TEXT,\n",
        "            var_historical REAL,\n",
        "            var_parametric REAL,\n",
        "            var_monte_carlo REAL,\n",
        "            cvar REAL,\n",
        "            mdd REAL,\n",
        "            omega_ratio REAL,\n",
        "            entropic_var REAL,\n",
        "            tail_risk REAL,\n",
        "            skewness REAL,\n",
        "            kurtosis REAL\n",
        "        )\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def fetch_data(self, start_date=None, end_date=None):\n",
        "        \"\"\"Fetch historical stock data\"\"\"\n",
        "        if start_date is None:\n",
        "            start_date = (datetime.now() - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
        "        if end_date is None:\n",
        "            end_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        data = yf.download(self.nifty50_tickers, start=start_date, end=end_date)['Adj Close']\n",
        "        return data\n",
        "\n",
        "    def calculate_returns(self, data):\n",
        "        \"\"\"Calculate daily returns\"\"\"\n",
        "        returns = data.pct_change().dropna()\n",
        "        return returns\n",
        "\n",
        "    def calculate_portfolio_returns(self, returns, weights=None):\n",
        "        \"\"\"Calculate portfolio returns based on weights\"\"\"\n",
        "        if weights is None:\n",
        "            # Equal weights if none provided\n",
        "            weights = np.ones(len(returns.columns)) / len(returns.columns)\n",
        "\n",
        "        portfolio_returns = returns.dot(weights)\n",
        "        return portfolio_returns\n",
        "\n",
        "    def calculate_var(self, returns, method='historical'):\n",
        "        \"\"\"Calculate Value at Risk using different methods\"\"\"\n",
        "        if method == 'historical':\n",
        "            return np.percentile(returns, self.alpha * 100)\n",
        "        elif method == 'parametric':\n",
        "            mean_ret = returns.mean()\n",
        "            std_dev = returns.std()\n",
        "            z_score = stats.norm.ppf(self.alpha)\n",
        "            return mean_ret + z_score * std_dev\n",
        "        elif method == 'monte_carlo':\n",
        "            np.random.seed(42)\n",
        "            simulated_returns = np.random.normal(returns.mean(), returns.std(), 10000)\n",
        "            return np.percentile(simulated_returns, self.alpha * 100)\n",
        "\n",
        "    def calculate_cvar(self, returns, var):\n",
        "        \"\"\"Calculate Conditional VaR (Expected Shortfall)\"\"\"\n",
        "        return returns[returns <= var].mean()\n",
        "\n",
        "    def calculate_mdd(self, returns):\n",
        "        \"\"\"Calculate Maximum Drawdown\"\"\"\n",
        "        cumulative_returns = (1 + returns).cumprod()\n",
        "        peak = cumulative_returns.cummax()\n",
        "        drawdown = (cumulative_returns - peak) / peak\n",
        "        return drawdown.min()\n",
        "\n",
        "    def calculate_omega_ratio(self, returns, threshold=0):\n",
        "        \"\"\"Calculate Omega Ratio\"\"\"\n",
        "        gains = returns[returns > threshold].sum()\n",
        "        losses = abs(returns[returns < threshold].sum())\n",
        "        return gains / losses if losses != 0 else np.nan\n",
        "\n",
        "    def calculate_entropic_var(self, returns, theta=1.0):\n",
        "        \"\"\"Calculate Entropic VaR using exponential utility\"\"\"\n",
        "        lambda_val = -np.log(self.alpha) / theta\n",
        "        return -np.log(np.mean(np.exp(-lambda_val * returns))) / lambda_val\n",
        "\n",
        "    def calculate_tail_risk(self, returns):\n",
        "        \"\"\"Calculate tail risk as probability of extreme loss\"\"\"\n",
        "        extreme_threshold = returns.mean() - 3 * returns.std()\n",
        "        return (returns < extreme_threshold).mean()\n",
        "\n",
        "    def analyze_return_distribution(self, returns):\n",
        "        \"\"\"Calculate skewness and kurtosis of returns\"\"\"\n",
        "        skewness = stats.skew(returns)\n",
        "        kurtosis = stats.kurtosis(returns)\n",
        "        return skewness, kurtosis\n",
        "\n",
        "    def add_technical_indicators(self, data):\n",
        "        \"\"\"Add technical indicators to data\"\"\"\n",
        "        result = {}\n",
        "        for column in data.columns:\n",
        "            series = data[column]\n",
        "            df = pd.DataFrame(series)\n",
        "            df.columns = ['close']\n",
        "\n",
        "            # Calculate RSI\n",
        "            df['RSI'] = ta.momentum.RSIIndicator(df['close']).rsi()\n",
        "\n",
        "            # Calculate Moving Averages\n",
        "            df['SMA_20'] = ta.trend.SMAIndicator(df['close'], window=20).sma_indicator()\n",
        "            df['SMA_50'] = ta.trend.SMAIndicator(df['close'], window=50).sma_indicator()\n",
        "            df['SMA_200'] = ta.trend.SMAIndicator(df['close'], window=200).sma_indicator()\n",
        "\n",
        "            # Calculate Bollinger Bands\n",
        "            bollinger = ta.volatility.BollingerBands(df['close'])\n",
        "            df['Bollinger_upper'] = bollinger.bollinger_hband()\n",
        "            df['Bollinger_lower'] = bollinger.bollinger_lband()\n",
        "            df['Bollinger_pct'] = bollinger.bollinger_pband()\n",
        "\n",
        "            # Calculate MACD\n",
        "            macd = ta.trend.MACD(df['close'])\n",
        "            df['MACD'] = macd.macd()\n",
        "            df['MACD_signal'] = macd.macd_signal()\n",
        "            df['MACD_diff'] = macd.macd_diff()\n",
        "\n",
        "            result[column] = df.dropna()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def log_alert(self, alert_type, value, message):\n",
        "        \"\"\"Log alert to database\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO alerts (timestamp, alert_type, value, message)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "        \"\"\", (timestamp, alert_type, value, message))\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def log_risk_metrics(self, metrics):\n",
        "        \"\"\"Log risk metrics to database\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        columns = ', '.join(metrics.keys())\n",
        "        placeholders = ', '.join(['?' for _ in metrics])\n",
        "        values = tuple(metrics.values())\n",
        "\n",
        "        query = f\"INSERT INTO risk_metrics (timestamp, {columns}) VALUES (?, {placeholders})\"\n",
        "        cursor.execute(query, (datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),) + values)\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    def generate_risk_metrics(self):\n",
        "        \"\"\"Generate all risk metrics\"\"\"\n",
        "        # Fetch data and calculate returns\n",
        "        data = self.fetch_data()\n",
        "        returns = self.calculate_returns(data)\n",
        "        portfolio_returns = self.calculate_portfolio_returns(returns)\n",
        "\n",
        "        # Calculate VaR metrics\n",
        "        var_historical = self.calculate_var(portfolio_returns, 'historical')\n",
        "        var_parametric = self.calculate_var(portfolio_returns, 'parametric')\n",
        "        var_monte_carlo = self.calculate_var(portfolio_returns, 'monte_carlo')\n",
        "\n",
        "        # Calculate other risk metrics\n",
        "        cvar = self.calculate_cvar(portfolio_returns, var_historical)\n",
        "        mdd = self.calculate_mdd(portfolio_returns)\n",
        "        omega_ratio = self.calculate_omega_ratio(portfolio_returns)\n",
        "        entropic_var = self.calculate_entropic_var(portfolio_returns)\n",
        "        tail_risk = self.calculate_tail_risk(portfolio_returns)\n",
        "        skewness, kurtosis = self.analyze_return_distribution(portfolio_returns)\n",
        "\n",
        "        # Create metrics dictionary\n",
        "        metrics = {\n",
        "            'var_historical': var_historical,\n",
        "            'var_parametric': var_parametric,\n",
        "            'var_monte_carlo': var_monte_carlo,\n",
        "            'cvar': cvar,\n",
        "            'mdd': mdd,\n",
        "            'omega_ratio': omega_ratio,\n",
        "            'entropic_var': entropic_var,\n",
        "            'tail_risk': tail_risk,\n",
        "            'skewness': skewness,\n",
        "            'kurtosis': kurtosis\n",
        "        }\n",
        "\n",
        "        # Log metrics to database\n",
        "        self.log_risk_metrics(metrics)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def plot_risk_metrics(self, returns):\n",
        "        \"\"\"Generate plots for risk metrics\"\"\"\n",
        "        # Calculate VaR\n",
        "        var_historical = self.calculate_var(returns, 'historical')\n",
        "\n",
        "        # Create VaR plot\n",
        "        fig_var = px.histogram(returns, title=\"Return Distribution with VaR\")\n",
        "        fig_var.add_vline(x=var_historical, line_dash=\"dash\", line_color=\"red\",\n",
        "                          annotation_text=f\"VaR (95%): {var_historical:.4f}\")\n",
        "\n",
        "        # Create drawdown plot\n",
        "        cumulative_returns = (1 + returns).cumprod()\n",
        "        peak = cumulative_returns.cummax()\n",
        "        drawdown = (cumulative_returns - peak) / peak\n",
        "        fig_dd = px.line(drawdown, title=\"Drawdown Over Time\")\n",
        "        fig_dd.add_hline(y=drawdown.min(), line_dash=\"dash\", line_color=\"red\",\n",
        "                         annotation_text=f\"MDD: {drawdown.min():.4f}\")\n",
        "\n",
        "        return fig_var, fig_dd\n",
        "\n",
        "    def simulate_market_stress(self, returns, scenario='market_crash'):\n",
        "        \"\"\"Simulate stress scenarios\"\"\"\n",
        "        if scenario == 'market_crash':\n",
        "            # Simulate 2008-like crash (approximately double volatility, negative shift)\n",
        "            stress_returns = returns * 2.0 - 0.01\n",
        "        elif scenario == 'interest_rate_hike':\n",
        "            # Interest rate hikes tend to affect markets less severely but more persistently\n",
        "            stress_returns = returns * 1.5 - 0.005\n",
        "        elif scenario == 'liquidity_crisis':\n",
        "            # Liquidity crises can cause extreme but short-lived volatility\n",
        "            stress_returns = returns * 2.5 - 0.015\n",
        "        else:\n",
        "            stress_returns = returns\n",
        "\n",
        "        # Calculate stress scenario metrics\n",
        "        stress_var = self.calculate_var(stress_returns, 'historical')\n",
        "        stress_cvar = self.calculate_cvar(stress_returns, stress_var)\n",
        "\n",
        "        return {\n",
        "            'scenario': scenario,\n",
        "            'stress_var': stress_var,\n",
        "            'stress_cvar': stress_cvar,\n",
        "            'stress_returns': stress_returns\n",
        "        }"
      ],
      "metadata": {
        "id": "f2_mn3CyVQG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PortfolioOptimizer:\n",
        "    def __init__(self, risk_model):\n",
        "        self.risk_model = risk_model\n",
        "\n",
        "    def mean_variance_optimization(self, returns, risk_free_rate=0.0, target_return=None):\n",
        "        \"\"\"Traditional Markowitz Mean-Variance Optimization\"\"\"\n",
        "        n = len(returns.columns)\n",
        "        returns_mean = returns.mean()\n",
        "        cov_matrix = returns.cov()\n",
        "\n",
        "        # Define optimization objective: minimize portfolio variance\n",
        "        def portfolio_variance(weights):\n",
        "            return np.dot(weights.T, np.dot(cov_matrix, weights))\n",
        "\n",
        "        # Define constraints\n",
        "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # weights sum to 1\n",
        "\n",
        "        # Add target return constraint if specified\n",
        "        if target_return is not None:\n",
        "            constraints.append({\n",
        "                'type': 'eq',\n",
        "                'fun': lambda w: np.dot(w, returns_mean) - target_return\n",
        "            })\n",
        "\n",
        "        # Define bounds (no short selling)\n",
        "        bounds = tuple((0, 1) for _ in range(n))\n",
        "\n",
        "        # Initial guess\n",
        "        initial_weights = np.ones(n) / n\n",
        "\n",
        "        # Optimize\n",
        "        from scipy.optimize import minimize\n",
        "        result = minimize(\n",
        "            portfolio_variance,\n",
        "            initial_weights,\n",
        "            method='SLSQP',\n",
        "            bounds=bounds,\n",
        "            constraints=constraints\n",
        "        )\n",
        "\n",
        "        # Calculate portfolio metrics\n",
        "        weights = result['x']\n",
        "        portfolio_return = np.dot(weights, returns_mean)\n",
        "        portfolio_volatility = np.sqrt(portfolio_variance(weights))\n",
        "        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_volatility\n",
        "\n",
        "        return {\n",
        "            'weights': dict(zip(returns.columns, weights)),\n",
        "            'return': portfolio_return,\n",
        "            'volatility': portfolio_volatility,\n",
        "            'sharpe_ratio': sharpe_ratio\n",
        "        }\n",
        "\n",
        "    def mean_cvar_optimization(self, returns, alpha=0.05, target_return=None):\n",
        "        \"\"\"Mean-CVaR Optimization for tail risk management\"\"\"\n",
        "        n = len(returns.columns)\n",
        "        returns_mean = returns.mean()\n",
        "\n",
        "        # Calculate portfolio CVaR\n",
        "        def portfolio_cvar(weights):\n",
        "            portfolio_returns = returns.dot(weights)\n",
        "            var = np.percentile(portfolio_returns, alpha * 100)\n",
        "            cvar = portfolio_returns[portfolio_returns <= var].mean()\n",
        "            return -cvar  # Negative because we want to maximize CVaR\n",
        "\n",
        "        # Define constraints\n",
        "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # weights sum to 1\n",
        "\n",
        "        # Add target return constraint if specified\n",
        "        if target_return is not None:\n",
        "            constraints.append({\n",
        "                'type': 'eq',\n",
        "                'fun': lambda w: np.dot(w, returns_mean) - target_return\n",
        "            })\n",
        "\n",
        "        # Define bounds (no short selling)\n",
        "        bounds = tuple((0, 1) for _ in range(n))\n",
        "\n",
        "        # Initial guess\n",
        "        initial_weights = np.ones(n) / n\n",
        "\n",
        "        # Optimize\n",
        "        from scipy.optimize import minimize\n",
        "        result = minimize(\n",
        "            portfolio_cvar,\n",
        "            initial_weights,\n",
        "            method='SLSQP',\n",
        "            bounds=bounds,\n",
        "            constraints=constraints\n",
        "        )\n",
        "\n",
        "        # Calculate portfolio metrics\n",
        "        weights = result['x']\n",
        "        portfolio_return = np.dot(weights, returns_mean)\n",
        "        portfolio_cvar = -portfolio_cvar(weights)\n",
        "\n",
        "        return {\n",
        "            'weights': dict(zip(returns.columns, weights)),\n",
        "            'return': portfolio_return,\n",
        "            'cvar': portfolio_cvar,\n",
        "            'cvar_ratio': portfolio_return / (-portfolio_cvar)\n",
        "        }\n",
        "\n",
        "    def black_litterman_optimization(self, returns, market_cap_weights, risk_aversion=2.5,\n",
        "                                    investor_views=None, view_confidences=None):\n",
        "        \"\"\"Black-Litterman Portfolio Optimization\"\"\"\n",
        "        # Calculate inputs\n",
        "        delta = risk_aversion\n",
        "        returns_mean = returns.mean()\n",
        "        cov_matrix = returns.cov()\n",
        "        n = len(returns.columns)\n",
        "\n",
        "        # Calculate implied market equilibrium returns\n",
        "        pi = delta * np.dot(cov_matrix, market_cap_weights)\n",
        "\n",
        "        # If investor views are provided, incorporate them\n",
        "        if investor_views is not None and view_confidences is not None:\n",
        "            # P: picks matrix for views\n",
        "            P = np.zeros((len(investor_views), n))\n",
        "            for i, (asset_idx, _) in enumerate(investor_views):\n",
        "                P[i, asset_idx] = 1\n",
        "\n",
        "            # Q: view return vector\n",
        "            Q = np.array([view[1] for view in investor_views])\n",
        "\n",
        "            # Omega: view uncertainty/confidence\n",
        "            Omega = np.diag([1/conf for conf in view_confidences])\n",
        "\n",
        "            # Compute posterior returns\n",
        "            tau = 0.05  # Scaling factor for prior uncertainty\n",
        "            pi_adj = np.linalg.inv(\n",
        "                np.linalg.inv(tau * cov_matrix) + np.dot(P.T, np.dot(np.linalg.inv(Omega), P))\n",
        "            )\n",
        "            pi_adj = np.dot(pi_adj,\n",
        "                          np.dot(np.linalg.inv(tau * cov_matrix), pi) +\n",
        "                          np.dot(P.T, np.dot(np.linalg.inv(Omega), Q)))\n",
        "        else:\n",
        "            pi_adj = pi\n",
        "\n",
        "        # Define portfolio optimization problem\n",
        "        def portfolio_objective(weights):\n",
        "            return -(np.dot(weights, pi_adj) - 0.5 * delta *\n",
        "                    np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "\n",
        "        # Constraints and bounds\n",
        "        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
        "        bounds = tuple((0, 1) for _ in range(n))\n",
        "\n",
        "        # Initial guess\n",
        "        initial_weights = np.ones(n) / n\n",
        "\n",
        "        # Optimize\n",
        "        from scipy.optimize import minimize\n",
        "        result = minimize(\n",
        "            portfolio_objective,\n",
        "            initial_weights,\n",
        "            method='SLSQP',\n",
        "            bounds=bounds,\n",
        "            constraints=constraints\n",
        "        )\n",
        "\n",
        "        # Calculate portfolio metrics\n",
        "        weights = result['x']\n",
        "        portfolio_return = np.dot(weights, returns_mean)\n",
        "        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "        sharpe_ratio = portfolio_return / portfolio_volatility\n",
        "\n",
        "        return {\n",
        "            'weights': dict(zip(returns.columns, weights)),\n",
        "            'return': portfolio_return,\n",
        "            'volatility': portfolio_volatility,\n",
        "            'sharpe_ratio': sharpe_ratio\n",
        "        }\n",
        "\n",
        "    def generate_efficient_frontier(self, returns, points=20):\n",
        "        \"\"\"Generate efficient frontier points\"\"\"\n",
        "        # Calculate return range\n",
        "        min_return = returns.mean().min()\n",
        "        max_return = returns.mean().max()\n",
        "        target_returns = np.linspace(min_return, max_return, points)\n",
        "\n",
        "        # Calculate efficient frontier points\n",
        "        results = []\n",
        "        for target_return in target_returns:\n",
        "            result = self.mean_variance_optimization(returns, target_return=target_return)\n",
        "            results.append({\n",
        "                'return': result['return'],\n",
        "                'volatility': result['volatility'],\n",
        "                'sharpe_ratio': result['sharpe_ratio']\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def optimize_and_rebalance(self, method='mean_variance'):\n",
        "        \"\"\"Run optimization and suggest rebalancing\"\"\"\n",
        "        # Fetch data\n",
        "        data = self.risk_model.fetch_data()\n",
        "        returns = self.risk_model.calculate_returns(data)\n",
        "\n",
        "        # Run appropriate optimization\n",
        "        if method == 'mean_variance':\n",
        "            result = self.mean_variance_optimization(returns)\n",
        "        elif method == 'mean_cvar':\n",
        "            result = self.mean_cvar_optimization(returns)\n",
        "        elif method == 'black_litterman':\n",
        "            # Approximate market cap weights using latest prices and equal shares\n",
        "            latest_prices = data.iloc[-1]\n",
        "            market_cap_weights = latest_prices / latest_prices.sum()\n",
        "            result = self.black_litterman_optimization(returns, market_cap_weights)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown optimization method: {method}\")\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "-hb_TDTeVtis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MachineLearningModels:\n",
        "    def __init__(self, risk_model):\n",
        "        self.risk_model = risk_model\n",
        "        self.models_path = \"/content/drive/MyDrive/NiftyRiskModel/models/\"\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "        # Ensure models directory exists\n",
        "        os.makedirs(self.models_path, exist_ok=True)\n",
        "\n",
        "    def prepare_features(self, returns, window=5):\n",
        "        \"\"\"Prepare features for ML models\"\"\"\n",
        "        # Calculate rolling statistics\n",
        "        features = pd.DataFrame(index=returns.index)\n",
        "\n",
        "        # Add lagged returns\n",
        "        for i in range(1, window+1):\n",
        "            features[f'lag_{i}'] = returns.shift(i)\n",
        "\n",
        "        # Add rolling mean and std\n",
        "        features['rolling_mean'] = returns.rolling(window=window).mean()\n",
        "        features['rolling_std'] = returns.rolling(window=window).std()\n",
        "\n",
        "        # Add rolling min and max\n",
        "        features['rolling_min'] = returns.rolling(window=window).min()\n",
        "        features['rolling_max'] = returns.rolling(window=window).max()\n",
        "\n",
        "        # Add rolling skew and kurt\n",
        "        features['rolling_skew'] = returns.rolling(window=window).skew()\n",
        "        features['rolling_kurt'] = returns.rolling(window=window).apply(lambda x: stats.kurtosis(x))\n",
        "\n",
        "        return features.dropna()\n",
        "\n",
        "    def train_random_forest(self, returns, forecast_horizon=5):\n",
        "        \"\"\"Train a Random Forest model to predict VaR\"\"\"\n",
        "        # Prepare features and target\n",
        "        features = self.prepare_features(returns)\n",
        "\n",
        "        # Target: future minimum return over forecast horizon\n",
        "        future_mins = pd.Series(index=features.index)\n",
        "        for i in features.index:\n",
        "            future_window = returns.loc[i:].iloc[:forecast_horizon]\n",
        "            if len(future_window) == forecast_horizon:\n",
        "                future_mins.loc[i] = future_window.min()\n",
        "\n",
        "        # Drop rows with missing targets\n",
        "        valid_indices = future_mins.dropna().index\n",
        "        X = features.loc[valid_indices]\n",
        "        y = future_mins.loc[valid_indices]\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Train model\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Save model\n",
        "        model_file = os.path.join(self.models_path, 'random_forest_var.pkl')\n",
        "        with open(model_file, 'wb') as f:\n",
        "            pickle.dump((model, self.scaler), f)\n",
        "\n",
        "        # Evaluate\n",
        "        score = model.score(X_test, y_test)\n",
        "        predictions = model.predict(X_test)\n",
        "        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
        "\n",
        "        return {\n",
        "            'model': model,\n",
        "            'r2_score': score,\n",
        "            'rmse': rmse,\n",
        "            'feature_importance': dict(zip(X.columns, model.feature_importances_))\n",
        "        }\n",
        "\n",
        "    def train_lstm(self, returns, forecast_horizon=5, epochs=50):\n",
        "        \"\"\"Train an LSTM model to predict VaR\"\"\"\n",
        "        # Prepare features and target\n",
        "        features = self.prepare_features(returns)\n",
        "\n",
        "        # Target: future minimum return over forecast horizon\n",
        "        future_mins = pd.Series(index=features.index)\n",
        "        for i in features.index:\n",
        "            future_window = returns.loc[i:].iloc[:forecast_horizon]\n",
        "            if len(future_window) == forecast_horizon:\n",
        "                future_mins.loc[i] = future_window.min()\n",
        "\n",
        "        # Drop rows with missing targets\n",
        "        valid_indices = future_mins.dropna().index\n",
        "        X = features.loc[valid_indices]\n",
        "        y = future_mins.loc[valid_indices]\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Reshape for LSTM [samples, timesteps, features]\n",
        "        X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
        "\n",
        "        # Train-test split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Build LSTM model\n",
        "        model = Sequential([\n",
        "            LSTM(50, return_sequences=True, input_shape=(1, X_train.shape[2])),\n",
        "            Dropout(0.2),\n",
        "            LSTM(50, return_sequences=False),\n",
        "            Dropout(0.2),\n",
        "            Dense(1)\n",
        "        ])\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        # Train model\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=epochs,\n",
        "            batch_size=32,\n",
        "            validation_data=(X_test, y_test),\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Save model\n",
        "        model_file = os.path.join(self.models_path, 'lstm_var_model.h5')\n",
        "        model.save(model_file)\n",
        "\n",
        "        # Evaluate\n",
        "        predictions = model.predict(X_test).flatten()\n",
        "        rmse = np.sqrt(np.mean((predictions - y_test) ** 2))\n",
        "        r2 = 1 - np.sum((y_test - predictions) ** 2) / np.sum((y_test - np.mean(y_test)) ** 2)\n",
        "\n",
        "        return {\n",
        "            'model': model,\n",
        "            'history': history.history,\n",
        "            'rmse': rmse,\n",
        "            'r2_score': r2\n",
        "        }\n",
        "\n",
        "    def predict_var(self, returns, method='random_forest'):\n",
        "        \"\"\"Predict VaR using trained models\"\"\"\n",
        "        # Prepare features\n",
        "        features = self.prepare_features(returns)\n",
        "        latest_features = features.iloc[-1:]\n",
        "\n",
        "        if method == 'random_forest':\n",
        "            # Load model\n",
        "            model_file = os.path.join(self.models_path, 'random_forest_var.pkl')\n",
        "            try:\n",
        "                with open(model_file, 'rb') as f:\n",
        "                    model, scaler = pickle.load(f)\n",
        "\n",
        "                # Scale features\n",
        "                latest_scaled = scaler.transform(latest_features)\n",
        "\n",
        "                # Predict\n",
        "                prediction = model.predict(latest_scaled)[0]\n",
        "                return prediction\n",
        "            except FileNotFoundError:\n",
        "                print(\"Model file not found. Please train the model first.\")\n",
        "                return None\n",
        "\n",
        "        elif method == 'lstm':\n",
        "            # Load model\n",
        "            model_file = os.path.join(self.models_path, 'lstm_var_model.h5')\n",
        "            try:\n",
        "                model = tf.keras.models.load_model(model_file)\n",
        "\n",
        "                # Scale features\n",
        "                latest_scaled = self.scaler.transform(latest_features)\n",
        "\n",
        "                # Reshape for LSTM\n",
        "                latest_reshaped = latest_scaled.reshape((latest_scaled.shape[0], 1, latest_scaled.shape[1]))\n",
        "\n",
        "                # Predict\n",
        "                prediction = model.predict(latest_reshaped)[0][0]\n",
        "                return prediction\n",
        "            except:\n",
        "                print(\"Model file not found or error loading model. Please train the model first.\")\n",
        "                return None\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown prediction method: {method}\")\n",
        "\n",
        "    def detect_market_crash_pattern(self, returns, window=90):\n",
        "        \"\"\"Detect patterns similar to past market crashes\"\"\"\n",
        "        # Calculate rolling correlation with 2008 financial crisis pattern\n",
        "        # This is a simplified example - you would ideally use actual historical crash data\n",
        "        crash_pattern = np.linspace(0, -0.5, window) + np.random.normal(0, 0.05, window)\n",
        "\n",
        "        # Calculate rolling correlation\n",
        "        correlations = []\n",
        "        for i in range(window, len(returns)):\n",
        "            current_window = returns.iloc[i-window:i].values\n",
        "            correlation = np.corrcoef(crash_pattern, current_window)[0, 1]\n",
        "            correlations.append(correlation)\n",
        "\n",
        "        correlation_series = pd.Series(correlations, index=returns.index[window:])\n",
        "\n",
        "        # Detect high correlation as potential crash pattern\n",
        "        threshold = 0.7\n",
        "        crash_signals = correlation_series[correlation_series > threshold]\n",
        "\n",
        "        return crash_signals\n",
        "\n",
        "    def run_all_models(self):\n",
        "        \"\"\"Run all ML models and return predictions\"\"\"\n",
        "        # Fetch data\n",
        "        data = self.risk_model.fetch_data()\n",
        "        returns = self.risk_model.calculate_returns(data)\n",
        "        portfolio_returns = self.risk_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "        # Train models if they don't exist\n",
        "        if not os.path.exists(os.path.join(self.models_path, 'random_forest_var.pkl')):\n",
        "            print(\"Training Random Forest model...\")\n",
        "            self.train_random_forest(portfolio_returns)\n",
        "\n",
        "        if not os.path.exists(os.path.join(self.models_path, 'lstm_var_model.h5')):\n",
        "            print(\"Training LSTM model...\")\n",
        "            self.train_lstm(portfolio_returns, epochs=10)  # Reduced epochs for Colab\n",
        "\n",
        "        # Get predictions\n",
        "        rf_prediction = self.predict_var(portfolio_returns, 'random_forest')\n",
        "        lstm_prediction = self.predict_var(portfolio_returns, 'lstm')\n",
        "\n",
        "        # Detect crash patterns\n",
        "        crash_signals = self.detect_market_crash_pattern(portfolio_returns)"
      ],
      "metadata": {
        "id": "8RVK04oXV3qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataIntegration:\n",
        "    def __init__(self):\n",
        "        self.alpha_vantage_key = \"YOUR_ALPHA_VANTAGE_KEY\"  # Replace with your key or use secrets in Colab\n",
        "        self.newsapi_key = \"YOUR_NEWSAPI_KEY\"  # Replace with your key\n",
        "        self.global_indices = {\n",
        "            \"^GSPC\": \"S&P 500\",\n",
        "            \"^IXIC\": \"NASDAQ\",\n",
        "            \"^DJI\": \"Dow Jones\",\n",
        "            \"^FTSE\": \"FTSE 100\",\n",
        "            \"^N225\": \"Nikkei 225\",\n",
        "            \"^HSI\": \"Hang Seng\"\n",
        "        }\n",
        "\n",
        "    def fetch_nifty50_data(self, period=\"1y\"):\n",
        "        \"\"\"Fetch NIFTY 50 stocks data\"\"\"\n",
        "        nifty50_tickers = [\n",
        "            \"RELIANCE.NS\", \"TCS.NS\", \"INFY.NS\", \"HDFCBANK.NS\", \"ICICIBANK.NS\",\n",
        "            \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"KOTAKBANK.NS\", \"LT.NS\"\n",
        "        ]\n",
        "        data = yf.download(nifty50_tickers, period=period)['Adj Close']\n",
        "        return data\n",
        "\n",
        "    def fetch_global_indices(self, period=\"1y\"):\n",
        "        \"\"\"Fetch global market indices\"\"\"\n",
        "        indices_data = yf.download(list(self.global_indices.keys()), period=period)['Adj Close']\n",
        "        # Rename columns for better readability\n",
        "        indices_data.columns = [self.global_indices[ticker] for ticker in self.global_indices.keys()]\n",
        "        return indices_data\n",
        "\n",
        "    def fetch_bond_yields(self):\n",
        "        \"\"\"Fetch US and Indian government bond yields\"\"\"\n",
        "        tickers = [\n",
        "            \"^TNX\",      # US 10-Year Treasury Yield\n",
        "            \"^TYX\",      # US 30-Year Treasury Yield\n",
        "            \"^IRX\"       # US 13-Week Treasury Bill\n",
        "        ]\n",
        "\n",
        "        bond_data = yf.download(tickers, period=\"1mo\")['Adj Close']\n",
        "        bond_data.columns = [\"US 10Y\", \"US 30Y\", \"US 13W\"]\n",
        "\n",
        "        return bond_data\n",
        "\n",
        "    def fetch_macro_indicators(self):\n",
        "        \"\"\"Fetch macroeconomic indicators from Alpha Vantage\"\"\"\n",
        "        if not self.alpha_vantage_key or self.alpha_vantage_key == \"YOUR_ALPHA_VANTAGE_KEY\":\n",
        "            print(\"Warning: Alpha Vantage API key not set\")\n",
        "            return pd.DataFrame({\"Error\": [\"Alpha Vantage API key not found\"]})\n",
        "\n",
        "        indicators = {}\n",
        "\n",
        "        # Fetch real GDP\n",
        "        try:\n",
        "            url = f\"https://www.alphavantage.co/query?function=REAL_GDP&interval=quarterly&apikey={self.alpha_vantage_key}\"\n",
        "            r = requests.get(url)\n",
        "            data = r.json()\n",
        "            gdp_data = data.get('data', [])\n",
        "            if gdp_data:\n",
        "                latest_gdp = {\n",
        "                    'date': gdp_data[0]['date'],\n",
        "                    'value': float(gdp_data[0]['value'])\n",
        "                }\n",
        "                indicators[\"Real GDP\"] = latest_gdp\n",
        "        except Exception as e:\n",
        "            indicators[\"Real GDP Error\"] = str(e)\n",
        "\n",
        "        # Fetch inflation\n",
        "        try:\n",
        "            url = f\"https://www.alphavantage.co/query?function=INFLATION&apikey={self.alpha_vantage_key}\"\n",
        "            r = requests.get(url)\n",
        "            data = r.json()\n",
        "            inflation_data = data.get('data', [])\n",
        "            if inflation_data:\n",
        "                latest_inflation = {\n",
        "                    'date': inflation_data[0]['date'],\n",
        "                    'value': float(inflation_data[0]['value'])\n",
        "                }\n",
        "                indicators[\"Inflation\"] = latest_inflation\n",
        "        except Exception as e:\n",
        "            indicators[\"Inflation Error\"] = str(e)\n",
        "\n",
        "        return indicators\n",
        "\n",
        "    def fetch_financial_news(self, query=\"stock market\", days=7):\n",
        "        \"\"\"Fetch financial news using NewsAPI\"\"\"\n",
        "        if not self.newsapi_key or self.newsapi_key == \"YOUR_NEWSAPI_KEY\":\n",
        "            print(\"Warning: NewsAPI key not set\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            from_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
        "            url = f\"https://newsapi.org/v2/everything?q={query}&from={from_date}&sortBy=popularity&apiKey={self.newsapi_key}\"\n",
        "\n",
        "            response = requests.get(url)\n",
        "            articles = response.json().get('articles', [])\n",
        "\n",
        "            news_data = []\n",
        "            for article in articles[:10]:  # Get top 10 articles\n",
        "                news_data.append({\n",
        "                    'title': article.get('title'),\n",
        "                    'source': article.get('source', {}).get('name'),\n",
        "                    'published_at': article.get('publishedAt'),\n",
        "                    'url': article.get('url'),\n",
        "                    'description': article.get('description')\n",
        "                })\n",
        "\n",
        "            return news_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching news: {e}\")\n",
        "            return [{'error': str(e)}]\n",
        "\n",
        "    def fetch_forex_data(self, pairs=[\"USDINR=X\", \"EURINR=X\"]):\n",
        "        \"\"\"Fetch forex exchange rates\"\"\"\n",
        "        try:\n",
        "            forex_data = yf.download(pairs, period=\"1mo\")['Adj Close']\n",
        "            return forex_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching forex data: {e}\")\n",
        "            return pd.DataFrame({\"Error\": [str(e)]})\n",
        "\n",
        "    def fetch_options_data(self, ticker=\"^NSEI\", expiration_date=None):\n",
        "        \"\"\"Fetch options chain data for analysis\"\"\"\n",
        "        try:\n",
        "            ticker_obj = yf.Ticker(ticker)\n",
        "\n",
        "            # Get the next expiration date if not specified\n",
        "            if expiration_date is None:\n",
        "                expirations = ticker_obj.options\n",
        "                if expirations:\n",
        "                    expiration_date = expirations[0]\n",
        "                else:\n",
        "                    return {\"error\": \"No options expirations available\"}\n",
        "\n",
        "            # Fetch options data\n",
        "            options = ticker_obj.option_chain(expiration_date)\n",
        "\n",
        "            # Calculate put/call ratio\n",
        "            put_volume = options.puts['volume'].sum()\n",
        "            call_volume = options.calls['volume'].sum()\n",
        "            put_call_ratio = put_volume / call_volume if call_volume else 0\n",
        "\n",
        "            # Calculate implied volatility\n",
        "            calls_iv = options.calls['impliedVolatility'].mean()\n",
        "            puts_iv = options.puts['impliedVolatility'].mean()\n",
        "            avg_iv = (calls_iv + puts_iv) / 2\n",
        "\n",
        "            return {\n",
        "                'expiration_date': expiration_date,\n",
        "                'put_call_ratio': put_call_ratio,\n",
        "                'implied_volatility': avg_iv,\n",
        "                'calls_count': len(options.calls),\n",
        "                'puts_count': len(options.puts)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching options data: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "    def integrate_all_data(self):\n",
        "        \"\"\"Fetch and integrate all data sources\"\"\"\n",
        "        result = {}\n",
        "\n",
        "        # Fetch NIFTY 50 data\n",
        "        result['nifty50'] = self.fetch_nifty50_data()\n",
        "\n",
        "        # Fetch global indices\n",
        "        result['global_indices'] = self.fetch_global_indices()\n",
        "\n",
        "        # Fetch bond yields\n",
        "        result['bond_yields'] = self.fetch_bond_yields()\n",
        "\n",
        "        # Fetch forex data\n",
        "        result['forex'] = self.fetch_forex_data()\n",
        "\n",
        "        # Fetch options data\n",
        "        result['options'] = self.fetch_options_data()\n",
        "\n",
        "        return result"
      ],
      "metadata": {
        "id": "t4CAb3a_V-Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentAnalysis:\n",
        "    def __init__(self):\n",
        "        self.fear_terms = [\n",
        "            \"stock market crash\",\n",
        "            \"market crash\",\n",
        "            \"bear market\",\n",
        "            \"recession\",\n",
        "            \"financial crisis\"\n",
        "        ]\n",
        "        self.greed_terms = [\n",
        "            \"best stocks to buy\",\n",
        "            \"stock market opportunity\",\n",
        "            \"bull market\",\n",
        "            \"market rally\",\n",
        "            \"stock investing\"\n",
        "        ]\n",
        "\n",
        "    def fetch_google_trends(self, terms, timeframe='today 3-m'):\n",
        "        \"\"\"Fetch Google Trends data for a list of terms\"\"\"\n",
        "        try:\n",
        "            from pytrends.request import TrendReq\n",
        "\n",
        "            pytrends = TrendReq(hl='en-US', tz=360)\n",
        "            pytrends.build_payload(terms, cat=0, timeframe=timeframe, geo='', gprop='')\n",
        "\n",
        "            trends_data = pytrends.interest_over_time()\n",
        "            if trends_data.empty:\n",
        "                print(\"No data returned from Google Trends\")\n",
        "                return pd.DataFrame()\n",
        "\n",
        "            return trends_data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching Google Trends data: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "    def calculate_fear_greed_index(self, timeframe='today 3-m'):\n",
        "        \"\"\"Calculate a Fear & Greed index based on Google Trends data\"\"\"\n",
        "        # Fetch fear terms trends\n",
        "        fear_trends = self.fetch_google_trends(self.fear_terms[:4], timeframe)  # Limit to 4 terms due to API limits\n",
        "\n",
        "        # Fetch greed terms trends\n",
        "        greed_trends = self.fetch_google_trends(self.greed_terms[:4], timeframe)\n",
        "\n",
        "        if fear_trends.empty or greed_trends.empty:\n",
        "            print(\"Could not calculate Fear & Greed index due to missing data\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Calculate aggregate fear and greed signals\n",
        "        fear_signal = fear_trends.mean(axis=1)\n",
        "        greed_signal = greed_trends.mean(axis=1)\n",
        "\n",
        "        # Create index dataframe\n",
        "        index_df = pd.DataFrame({\n",
        "            'fear': fear_signal,\n",
        "            'greed': greed_signal\n",
        "        })\n",
        "\n",
        "        # Calculate fear-greed index (0-100 scale where 0 is extreme fear and 100 is extreme greed)\n",
        "        index_df['fear_norm'] = (index_df['fear'] - index_df['fear'].min()) / (index_df['fear'].max() - index_df['fear'].min()) * 100\n",
        "        index_df['greed_norm'] = (index_df['greed'] - index_df['greed'].min()) / (index_df['greed'].max() - index_df['greed'].min()) * 100\n",
        "        index_df['fear_greed_index'] = 100 - index_df['fear_norm'] * 0.7 + index_df['greed_norm'] * 0.3\n",
        "\n",
        "        return index_df\n",
        "\n",
        "    def analyze_options_sentiment(self, options_data):\n",
        "        \"\"\"Analyze sentiment from options data\"\"\"\n",
        "        try:\n",
        "            put_call_ratio = options_data['put_call_ratio']\n",
        "            implied_volatility = options_data['implied_volatility']\n",
        "\n",
        "            # Interpret sentiment based on put-call ratio\n",
        "            # Typically, PCR > 1 is bearish, PCR < 0.7 is bullish\n",
        "            if put_call_ratio > 1.2:\n",
        "                pcr_sentiment = \"Strongly Bearish\"\n",
        "                pcr_score = 20 # 0-100 scale\n",
        "            elif put_call_ratio > 1.0:\n",
        "                pcr_sentiment = \"Bearish\"\n",
        "                pcr_score = 40\n",
        "            elif put_call_ratio > 0.8:\n",
        "                pcr_sentiment = \"Neutral\"\n",
        "                pcr_score = 50\n",
        "            elif put_call_ratio > 0.6:\n",
        "                pcr_sentiment = \"Bullish\"\n",
        "                pcr_score = 60\n",
        "            else:\n",
        "                pcr_sentiment = \"Strongly Bullish\"\n",
        "                pcr_score = 80\n",
        "\n",
        "            # Interpret sentiment based on implied volatility\n",
        "            # High IV suggests fear/uncertainty\n",
        "            iv_percentile = implied_volatility * 100  # Typically 0-1 scale to 0-100\n",
        "            if iv_percentile > 80:\n",
        "                iv_sentiment = \"High Fear\"\n",
        "                iv_score = 20\n",
        "            elif iv_percentile > 60:\n",
        "                iv_sentiment = \"Elevated Fear\"\n",
        "                iv_score = 40\n",
        "            elif iv_percentile > 40:\n",
        "                iv_sentiment = \"Neutral\"\n",
        "                iv_score = 50\n",
        "            elif iv_percentile > 20:\n",
        "                iv_sentiment = \"Low Fear\"\n",
        "                iv_score = 60\n",
        "            else:\n",
        "                iv_sentiment = \"Very Low Fear\"\n",
        "                iv_score = 80\n",
        "\n",
        "            # Combined sentiment score\n",
        "            combined_score = (pcr_score + iv_score) / 2\n",
        "\n",
        "            return {\n",
        "                'put_call_ratio': put_call_ratio,\n",
        "                'pcr_sentiment': pcr_sentiment,\n",
        "                'pcr_score': pcr_score,\n",
        "                'implied_volatility': implied_volatility,\n",
        "                'iv_sentiment': iv_sentiment,\n",
        "                'iv_score': iv_score,\n",
        "                'combined_score': combined_score\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error analyzing options sentiment: {e}\")\n",
        "            return {\"error\": str(e)}"
      ],
      "metadata": {
        "id": "gGFMYEptW_NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReportGenerator:\n",
        "    def __init__(self):\n",
        "        self.nifty_model = Nifty50RiskModel()\n",
        "        self.portfolio_optimizer = PortfolioOptimizer(self.nifty_model)\n",
        "        self.ml_models = MachineLearningModels(self.nifty_model)\n",
        "        self.data_integration = DataIntegration()\n",
        "        self.sentiment_analysis = SentimentAnalysis()\n",
        "\n",
        "    def generate_excel_report(self):\n",
        "        \"\"\"Generate a comprehensive Excel report with all risk metrics\"\"\"\n",
        "        from io import BytesIO\n",
        "\n",
        "        # Fetch data\n",
        "        data = self.nifty_model.fetch_data()\n",
        "        returns = self.nifty_model.calculate_returns(data)\n",
        "        portfolio_returns = self.nifty_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "        # Calculate risk metrics\n",
        "        var_historical = self.nifty_model.calculate_var(portfolio_returns, 'historical')\n",
        "        var_parametric = self.nifty_model.calculate_var(portfolio_returns, 'parametric')\n",
        "        var_monte_carlo = self.nifty_model.calculate_var(portfolio_returns, 'monte_carlo')\n",
        "        cvar = self.nifty_model.calculate_cvar(portfolio_returns, var_historical)\n",
        "        mdd = self.nifty_model.calculate_mdd(portfolio_returns)\n",
        "        omega_ratio = self.nifty_model.calculate_omega_ratio(portfolio_returns)\n",
        "\n",
        "        # Run portfolio optimization\n",
        "        mv_opt = self.portfolio_optimizer.optimize_and_rebalance('mean_variance')\n",
        "        cvar_opt = self.portfolio_optimizer.optimize_and_rebalance('mean_cvar')\n",
        "\n",
        "        # Create Excel buffer\n",
        "        output = BytesIO()\n",
        "        writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
        "\n",
        "        # Create summary sheet\n",
        "        summary_data = {\n",
        "            'Metric': ['Historical VaR (95%)', 'Parametric VaR (95%)', 'Monte Carlo VaR (95%)',\n",
        "                     'Conditional VaR (CVaR)', 'Maximum Drawdown (MDD)', 'Omega Ratio'],\n",
        "            'Value': [var_historical, var_parametric, var_monte_carlo, cvar, mdd, omega_ratio]\n",
        "        }\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        summary_df.to_excel(writer, sheet_name='Risk Metrics', index=False)\n",
        "\n",
        "        # Portfolio weights sheet\n",
        "        mv_weights = pd.DataFrame({\n",
        "            'Ticker': list(mv_opt['weights'].keys()),\n",
        "            'Mean-Variance Weight': list(mv_opt['weights'].values())\n",
        "        })\n",
        "        cvar_weights = pd.DataFrame({\n",
        "            'Ticker': list(cvar_opt['weights'].keys()),\n",
        "            'Mean-CVaR Weight': list(cvar_opt['weights'].values())\n",
        "        })\n",
        "        weights_df = mv_weights.merge(cvar_weights, on='Ticker')\n",
        "        weights_df.to_excel(writer, sheet_name='Portfolio Weights', index=False)\n",
        "\n",
        "        # Returns data sheet\n",
        "        returns.to_excel(writer, sheet_name='Historical Returns')\n",
        "\n",
        "        # Save the file\n",
        "        writer.close()\n",
        "        output.seek(0)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def generate_html_report(self):\n",
        "        \"\"\"Generate an HTML report for email\"\"\"\n",
        "        # Fetch data\n",
        "        data = self.nifty_model.fetch_data()\n",
        "        returns = self.nifty_model.calculate_returns(data)\n",
        "        portfolio_returns = self.nifty_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "        # Calculate risk metrics\n",
        "        var_historical = self.nifty_model.calculate_var(portfolio_returns, 'historical')\n",
        "        cvar = self.nifty_model.calculate_cvar(portfolio_returns, var_historical)\n",
        "        mdd = self.nifty_model.calculate_mdd(portfolio_returns)\n",
        "        omega_ratio = self.nifty_model.calculate_omega_ratio(portfolio_returns)\n",
        "\n",
        "        # Get ML predictions\n",
        "        try:\n",
        "            rf_prediction = self.ml_models.predict_var(portfolio_returns, 'random_forest')\n",
        "            lstm_prediction = self.ml_models.predict_var(portfolio_returns, 'lstm')\n",
        "        except:\n",
        "            rf_prediction = lstm_prediction = \"Model not trained\"\n",
        "\n",
        "        # Fetch options data for sentiment\n",
        "        options_data = self.data_integration.fetch_options_data()\n",
        "\n",
        "        # Create HTML report\n",
        "        html = f\"\"\"\n",
        "        <html>\n",
        "        <head>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; padding: 20px; }}\n",
        "                h1 {{ color: #2c3e50; }}\n",
        "                h2 {{ color: #3498db; }}\n",
        "                table {{ border-collapse: collapse; width: 100%; }}\n",
        "                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "                th {{ background-color: #f2f2f2; }}\n",
        "                .risk-high {{ color: #e74c3c; }}\n",
        "                .risk-medium {{ color: #f39c12; }}\n",
        "                .risk-low {{ color: #2ecc71; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <h1>NIFTY 50 Risk Report - {datetime.now().strftime('%Y-%m-%d')}</h1>\n",
        "\n",
        "            <h2>Key Risk Metrics</h2>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>Metric</th>\n",
        "                    <th>Value</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Historical VaR (95%)</td>\n",
        "                    <td class=\"risk-high\">{var_historical:.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Conditional VaR (CVaR)</td>\n",
        "                    <td class=\"risk-high\">{cvar:.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Maximum Drawdown (MDD)</td>\n",
        "                    <td class=\"risk-medium\">{mdd:.4f}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Omega Ratio</td>\n",
        "                    <td class=\"risk-low\">{omega_ratio:.4f}</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "\n",
        "            <h2>Machine Learning Predictions</h2>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>Model</th>\n",
        "                    <th>Predicted VaR</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Random Forest</td>\n",
        "                    <td>{rf_prediction if isinstance(rf_prediction, str) else f\"{rf_prediction:.4f}\"}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>LSTM Neural Network</td>\n",
        "                    <td>{lstm_prediction if isinstance(lstm_prediction, str) else f\"{lstm_prediction:.4f}\"}</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "\n",
        "            <h2>Market Sentiment</h2>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>Indicator</th>\n",
        "                    <th>Value</th>\n",
        "                    <th>Interpretation</th>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Put/Call Ratio</td>\n",
        "                    <td>{options_data.get('put_call_ratio', 'N/A')}</td>\n",
        "                    <td>{\"Bearish\" if options_data.get('put_call_ratio', 0) > 1 else \"Bullish\"}</td>\n",
        "                </tr>\n",
        "                <tr>\n",
        "                    <td>Implied Volatility</td>\n",
        "                    <td>{options_data.get('implied_volatility', 'N/A')}</td>\n",
        "                    <td>{\"High\" if options_data.get('implied_volatility', 0) > 0.3 else \"Low\"}</td>\n",
        "                </tr>\n",
        "            </table>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        return html\n",
        "\n",
        "    def simulate_email_alert(self, risk_threshold=-0.02):\n",
        "        \"\"\"Simulate email alert (for Colab, just prints the message)\"\"\"\n",
        "        # Fetch data\n",
        "        data = self.nifty_model.fetch_data()\n",
        "        returns = self.nifty_model.calculate_returns(data)\n",
        "        portfolio_returns = self.nifty_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "        # Calculate risk metrics\n",
        "        var_historical = self.nifty_model.calculate_var(portfolio_returns, 'historical')\n",
        "\n",
        "        # Check if risk threshold exceeded\n",
        "        if var_historical < risk_threshold:\n",
        "            alert_message = f\"\"\"\n",
        "            🚨 RISK ALERT: VaR Threshold Exceeded 🚨\n",
        "\n",
        "            Current VaR (95%): {var_historical:.4f}\n",
        "            Threshold: {risk_threshold:.4f}\n",
        "\n",
        "            Recommended Actions:\n",
        "            - Review portfolio allocations\n",
        "            - Consider hedging strategies\n",
        "            - Monitor market conditions closely\n",
        "\n",
        "            Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "            \"\"\"\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(alert_message)\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            # In a real implementation, this would send an email:\n",
        "            # send_email(subject=\"🚨 NIFTY 50 Risk Alert\", body=alert_message, recipients=[...])\n",
        "\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"\\nRisk within acceptable limits: VaR = {var_historical:.4f} > {risk_threshold:.4f}\")\n",
        "            return False"
      ],
      "metadata": {
        "id": "8qIX6wwqXEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab, we'll use plotly for interactive visualizations instead of Streamlit\n",
        "# Create a comprehensive dashboard using plotly\n",
        "\n",
        "def create_dashboard():\n",
        "    # Initialize models\n",
        "    risk_model = Nifty50RiskModel()\n",
        "    portfolio_optimizer = PortfolioOptimizer(risk_model)\n",
        "    ml_models = MachineLearningModels(risk_model)\n",
        "    data_integration = DataIntegration()\n",
        "\n",
        "    # Fetch data with proper error handling\n",
        "    print(\"Fetching NIFTY 50 data...\")\n",
        "    try:\n",
        "        data = risk_model.fetch_data()\n",
        "        if data.empty:\n",
        "            print(\"Error: Could not fetch NIFTY 50 data. Please check your internet connection.\")\n",
        "            return\n",
        "\n",
        "        # Calculate returns\n",
        "        returns = risk_model.calculate_returns(data)\n",
        "\n",
        "        # Make sure we have sufficient data\n",
        "        if len(returns) < 30:  # Need at least 30 data points for reliable metrics\n",
        "            print(\"Error: Insufficient data points for analysis.\")\n",
        "            return\n",
        "\n",
        "        # Calculate portfolio returns (with equal weights)\n",
        "        portfolio_returns = pd.Series(returns.mean(axis=1), index=returns.index, name=\"Portfolio\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Calculate key risk metrics inside try/except block to catch errors\n",
        "    try:\n",
        "        var_historical = risk_model.calculate_var(portfolio_returns, 'historical')\n",
        "        var_parametric = risk_model.calculate_var(portfolio_returns, 'parametric')\n",
        "        var_monte_carlo = risk_model.calculate_var(portfolio_returns, 'monte_carlo')\n",
        "        cvar = risk_model.calculate_cvar(portfolio_returns, var_historical)\n",
        "        mdd = risk_model.calculate_mdd(portfolio_returns)\n",
        "        omega_ratio = risk_model.calculate_omega_ratio(portfolio_returns)\n",
        "\n",
        "        # Print key metrics\n",
        "        print(\"\\n📊 NIFTY 50 Risk Metrics:\")\n",
        "        print(f\"Historical VaR (95%): {var_historical:.4f}\")\n",
        "        print(f\"Parametric VaR (95%): {var_parametric:.4f}\")\n",
        "        print(f\"Monte Carlo VaR (95%): {var_monte_carlo:.4f}\")\n",
        "        print(f\"Conditional VaR (CVaR): {cvar:.4f}\")\n",
        "        print(f\"Maximum Drawdown (MDD): {mdd:.4f}\")\n",
        "        print(f\"Omega Ratio: {omega_ratio:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating risk metrics: {e}\")\n",
        "        return\n",
        "\n",
        "    # Create return distribution plot\n",
        "    try:\n",
        "        fig_var = px.histogram(portfolio_returns,\n",
        "                             title=\"Portfolio Return Distribution with VaR\",\n",
        "                             labels={\"value\": \"Daily Return\", \"count\": \"Frequency\"})\n",
        "        fig_var.add_vline(x=var_historical, line_dash=\"dash\", line_color=\"red\",\n",
        "                      annotation_text=f\"VaR (95%): {var_historical:.4f}\")\n",
        "        fig_var.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating VaR plot: {e}\")\n",
        "\n",
        "    # Create cumulative returns plot\n",
        "    try:\n",
        "        cumulative_returns = (1 + portfolio_returns).cumprod()\n",
        "        fig_cumret = px.line(cumulative_returns,\n",
        "                           title=\"Cumulative Portfolio Returns\",\n",
        "                           labels={\"value\": \"Growth of $1\", \"index\": \"Date\"})\n",
        "        fig_cumret.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating cumulative returns plot: {e}\")\n",
        "\n",
        "    # Create drawdown plot\n",
        "    try:\n",
        "        peak = cumulative_returns.cummax()\n",
        "        drawdown = (cumulative_returns - peak) / peak\n",
        "        fig_dd = px.line(drawdown,\n",
        "                       title=\"Portfolio Drawdown\",\n",
        "                       labels={\"value\": \"Drawdown\", \"index\": \"Date\"})\n",
        "        fig_dd.add_hline(y=drawdown.min(), line_dash=\"dash\", line_color=\"red\",\n",
        "                     annotation_text=f\"MDD: {drawdown.min():.4f}\")\n",
        "        fig_dd.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating drawdown plot: {e}\")\n",
        "\n",
        "    # Run portfolio optimization\n",
        "    try:\n",
        "        print(\"\\n📈 Portfolio Optimization:\")\n",
        "\n",
        "        # Run Mean-Variance optimization\n",
        "        mv_opt = portfolio_optimizer.mean_variance_optimization(returns)\n",
        "        print(\"\\nMean-Variance Optimization:\")\n",
        "        print(f\"Expected Return: {mv_opt['return']:.4f}\")\n",
        "        print(f\"Volatility: {mv_opt['volatility']:.4f}\")\n",
        "        print(f\"Sharpe Ratio: {mv_opt['sharpe_ratio']:.4f}\")\n",
        "        print(\"Optimal Weights:\")\n",
        "        for ticker, weight in mv_opt['weights'].items():\n",
        "            print(f\"  {ticker}: {weight:.4f}\")\n",
        "\n",
        "        # Run Mean-CVaR optimization\n",
        "        cvar_opt = portfolio_optimizer.mean_cvar_optimization(returns)\n",
        "        print(\"\\nMean-CVaR Optimization:\")\n",
        "        print(f\"Expected Return: {cvar_opt['return']:.4f}\")\n",
        "        print(f\"CVaR: {cvar_opt['cvar']:.4f}\")\n",
        "        print(f\"CVaR Ratio: {cvar_opt['cvar_ratio']:.4f}\")\n",
        "        print(\"Optimal Weights:\")\n",
        "        for ticker, weight in cvar_opt['weights'].items():\n",
        "            print(f\"  {ticker}: {weight:.4f}\")\n",
        "\n",
        "        # Generate efficient frontier\n",
        "        ef = portfolio_optimizer.generate_efficient_frontier(returns, points=10)\n",
        "        fig_ef = px.scatter(ef, x='volatility', y='return', size='sharpe_ratio',\n",
        "                           title=\"Efficient Frontier\",\n",
        "                           labels={\"volatility\": \"Volatility (Risk)\", \"return\": \"Expected Return\"})\n",
        "        fig_ef.show()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in portfolio optimization: {e}\")\n",
        "\n",
        "    # ML-based predictions - with simplified approach for Colab\n",
        "    print(\"\\n🤖 ML Risk Predictions:\")\n",
        "    try:\n",
        "        # Simple ML prediction using Random Forest without requiring saved models\n",
        "        # This is a simplified version for Colab that trains a quick model on the fly\n",
        "        features = pd.DataFrame({\n",
        "            'rolling_mean': portfolio_returns.rolling(window=10).mean(),\n",
        "            'rolling_std': portfolio_returns.rolling(window=10).std(),\n",
        "            'rolling_min': portfolio_returns.rolling(window=10).min()\n",
        "        }).dropna()\n",
        "\n",
        "        # Target: 5-day minimum return (simplified VaR proxy)\n",
        "        target = pd.Series(index=features.index)\n",
        "        for i in range(len(features) - 5):\n",
        "            target.iloc[i] = portfolio_returns.iloc[i:i+5].min()\n",
        "        target = target.dropna()\n",
        "\n",
        "        # Align features and target\n",
        "        aligned_indices = features.index.intersection(target.index)\n",
        "        X = features.loc[aligned_indices]\n",
        "        y = target.loc[aligned_indices]\n",
        "\n",
        "        if len(X) > 10:  # Only proceed if we have enough data\n",
        "            # Simple model training\n",
        "            from sklearn.ensemble import RandomForestRegressor\n",
        "            model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
        "            model.fit(X, y)\n",
        "\n",
        "            # Make prediction using most recent data\n",
        "            latest_features = X.iloc[-1:]\n",
        "            prediction = model.fit(X, y).predict(latest_features)[0]\n",
        "\n",
        "            print(f\"Quick ML Prediction for 5-day VaR: {prediction:.4f}\")\n",
        "        else:\n",
        "            print(\"Insufficient data for ML prediction\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in ML predictions: {e}\")\n",
        "\n",
        "    # Fetch additional data sources\n",
        "    try:\n",
        "        print(\"\\n🌐 External Data Sources:\")\n",
        "        print(\"Fetching global indices...\")\n",
        "        global_indices = data_integration.fetch_global_indices(period='1mo')\n",
        "\n",
        "        if not global_indices.empty:\n",
        "            global_returns = global_indices.pct_change().dropna()\n",
        "\n",
        "            # Create correlation heatmap\n",
        "            global_corr = pd.concat([portfolio_returns.to_frame(), global_returns], axis=1).corr()\n",
        "            fig_corr = px.imshow(global_corr,\n",
        "                               title=\"Correlation with Global Indices\",\n",
        "                               labels=dict(color=\"Correlation\"),\n",
        "                               color_continuous_scale=\"RdBu_r\")\n",
        "            fig_corr.show()\n",
        "        else:\n",
        "            print(\"Could not fetch global indices data\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching external data: {e}\")\n",
        "\n",
        "    # Risk alert simulation\n",
        "    try:\n",
        "        print(\"\\n⚠️ Risk Alert Simulation:\")\n",
        "        risk_threshold = -0.02  # 2% loss threshold\n",
        "\n",
        "        if var_historical < risk_threshold:\n",
        "            alert_message = f\"\"\"\n",
        "            🚨 RISK ALERT: VaR Threshold Exceeded 🚨\n",
        "\n",
        "            Current VaR (95%): {var_historical:.4f}\n",
        "            Threshold: {risk_threshold:.4f}\n",
        "\n",
        "            Recommended Actions:\n",
        "            - Review portfolio allocations\n",
        "            - Consider hedging strategies\n",
        "            - Monitor market conditions closely\n",
        "\n",
        "            Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "            \"\"\"\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(alert_message)\n",
        "            print(\"=\"*50)\n",
        "        else:\n",
        "            print(f\"Risk within acceptable limits: VaR = {var_historical:.4f} > {risk_threshold:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in risk alert simulation: {e}\")\n",
        "\n",
        "    print(\"\\n✅ Dashboard generation complete!\")\n",
        "\n",
        "# Run the dashboard\n",
        "create_dashboard()"
      ],
      "metadata": {
        "id": "pv09GTQYZRrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_stress_testing():\n",
        "    risk_model = Nifty50RiskModel()\n",
        "\n",
        "    # Fetch data\n",
        "    data = risk_model.fetch_data()\n",
        "    returns = risk_model.calculate_returns(data)\n",
        "    portfolio_returns = risk_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "    # Calculate baseline VaR and CVaR\n",
        "    base_var = risk_model.calculate_var(portfolio_returns, 'historical')\n",
        "    base_cvar = risk_model.calculate_cvar(portfolio_returns, base_var)\n",
        "\n",
        "    print(\"\\n📊 Stress Testing Scenarios:\")\n",
        "    print(f\"Baseline VaR (95%): {base_var:.4f}\")\n",
        "    print(f\"Baseline CVaR: {base_cvar:.4f}\")\n",
        "\n",
        "    scenarios = [\n",
        "        'market_crash',\n",
        "        'interest_rate_hike',\n",
        "        'liquidity_crisis'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "    for scenario in scenarios:\n",
        "        stress_result = risk_model.simulate_market_stress(portfolio_returns, scenario)\n",
        "        results[scenario] = stress_result\n",
        "def run_stress_testing():\n",
        "    risk_model = Nifty50RiskModel()\n",
        "\n",
        "    # Fetch data\n",
        "    data = risk_model.fetch_data()\n",
        "    returns = risk_model.calculate_returns(data)\n",
        "    portfolio_returns = risk_model.calculate_portfolio_returns(returns)\n",
        "\n",
        "    # Calculate baseline VaR and CVaR\n",
        "    base_var = risk_model.calculate_var(portfolio_returns, 'historical')\n",
        "    base_cvar = risk_model.calculate_cvar(portfolio_returns, base_var)\n",
        "\n",
        "    print(\"\\n📊 Stress Testing Scenarios:\")\n",
        "    print(f\"Baseline VaR (95%): {base_var:.4f}\")\n",
        "    print(f\"Baseline CVaR: {base_cvar:.4f}\")\n",
        "\n",
        "    scenarios = [\n",
        "        'market_crash',\n",
        "        'interest_rate_hike',\n",
        "        'liquidity_crisis'\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "    for scenario in scenarios:\n",
        "        stress_result = risk_model.simulate_market_stress(portfolio_returns, scenario)\n",
        "        results[scenario] = stress_result\n",
        "\n",
        "        print(f\"\\n{scenario.replace('_', ' ').title()} Scenario:\")\n",
        "        print(f\"Stress VaR (95%): {stress_result['stress_var']:.4f} ({(stress_result['stress_var']/base_var - 1)*100:.2f}%)\")\n",
        "        print(f\"Stress CVaR: {stress_result['stress_cvar']:.4f}\")"
      ],
      "metadata": {
        "id": "TyXcRTRfbWDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_stress_testing():\n",
        "    risk_model = Nifty50RiskModel()\n",
        "\n",
        "    # Fetch data\n",
        "    print(\"Fetching NIFTY 50 data for stress testing...\")\n",
        "    try:\n",
        "        data = risk_model.fetch_data()\n",
        "        if data.empty:\n",
        "            print(\"Error: Could not fetch NIFTY 50 data for stress testing.\")\n",
        "            return\n",
        "\n",
        "        # Calculate returns\n",
        "        returns = risk_model.calculate_returns(data)\n",
        "        if len(returns) < 30:\n",
        "            print(\"Error: Insufficient data points for stress testing.\")\n",
        "            return\n",
        "\n",
        "        portfolio_returns = pd.Series(returns.mean(axis=1), index=returns.index, name=\"Portfolio\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data for stress testing: {e}\")\n",
        "        return\n",
        "\n",
        "    # Calculate baseline VaR and CVaR\n",
        "    try:\n",
        "        base_var = risk_model.calculate_var(portfolio_returns, 'historical')\n",
        "        base_cvar = risk_model.calculate_cvar(portfolio_returns, base_var)\n",
        "\n",
        "        print(\"\\n📊 Stress Testing Scenarios:\")\n",
        "        print(f\"Baseline VaR (95%): {base_var:.4f}\")\n",
        "        print(f\"Baseline CVaR: {base_cvar:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating baseline metrics: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define scenarios\n",
        "    scenarios = {\n",
        "        'market_crash': {\n",
        "            'description': '2008-like Market Crash',\n",
        "            'volatility_multiplier': 2.0,\n",
        "            'return_shift': -0.01\n",
        "        },\n",
        "        'interest_rate_hike': {\n",
        "            'description': 'Rapid Interest Rate Hike',\n",
        "            'volatility_multiplier': 1.5,\n",
        "            'return_shift': -0.005\n",
        "        },\n",
        "        'liquidity_crisis': {\n",
        "            'description': 'Liquidity Crisis',\n",
        "            'volatility_multiplier': 2.5,\n",
        "            'return_shift': -0.015\n",
        "        },\n",
        "        'sector_rotation': {\n",
        "            'description': 'Major Sector Rotation',\n",
        "            'volatility_multiplier': 1.7,\n",
        "            'return_shift': -0.007\n",
        "        },\n",
        "        'pandemic': {\n",
        "            'description': 'Pandemic-like Shock',\n",
        "            'volatility_multiplier': 3.0,\n",
        "            'return_shift': -0.02\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Run simulations for each scenario\n",
        "    results = {}\n",
        "    for scenario_name, scenario_params in scenarios.items():\n",
        "        try:\n",
        "            # Simulate stressed returns\n",
        "            stress_returns = portfolio_returns * scenario_params['volatility_multiplier'] + scenario_params['return_shift']\n",
        "\n",
        "            # Calculate stressed metrics\n",
        "            stress_var = risk_model.calculate_var(stress_returns, 'historical')\n",
        "            stress_cvar = risk_model.calculate_cvar(stress_returns, stress_var)\n",
        "\n",
        "            # Store results\n",
        "            results[scenario_name] = {\n",
        "                'description': scenario_params['description'],\n",
        "                'stress_var': stress_var,\n",
        "                'stress_cvar': stress_cvar,\n",
        "                'var_change': (stress_var / base_var - 1) * 100,  # percentage change\n",
        "                'cvar_change': (stress_cvar / base_cvar - 1) * 100  # percentage change\n",
        "            }\n",
        "\n",
        "            # Print results\n",
        "            print(f\"\\n{scenario_params['description']}:\")\n",
        "            print(f\"  Stress VaR (95%): {stress_var:.4f} ({results[scenario_name]['var_change']:.1f}% change)\")\n",
        "            print(f\"  Stress CVaR: {stress_cvar:.4f} ({results[scenario_name]['cvar_change']:.1f}% change)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in {scenario_name} scenario: {e}\")\n",
        "\n",
        "    # Visualize results\n",
        "    try:\n",
        "        # Prepare data for plotting\n",
        "        plot_data = []\n",
        "        for scenario, result in results.items():\n",
        "            plot_data.append({\n",
        "                'Scenario': result['description'],\n",
        "                'Metric': 'VaR',\n",
        "                'Value': abs(result['stress_var']),  # Taking absolute value for better visualization\n",
        "                'Change': result['var_change']\n",
        "            })\n",
        "            plot_data.append({\n",
        "                'Scenario': result['description'],\n",
        "                'Metric': 'CVaR',\n",
        "                'Value': abs(result['stress_cvar']),\n",
        "                'Change': result['cvar_change']\n",
        "            })\n",
        "\n",
        "        plot_df = pd.DataFrame(plot_data)\n",
        "\n",
        "        # Create bar chart\n",
        "        fig = px.bar(plot_df, x='Scenario', y='Value', color='Metric', barmode='group',\n",
        "                    title=\"Stress Test Results - Risk Metrics by Scenario\",\n",
        "                    labels={'Value': 'Absolute Risk Value', 'Scenario': '', 'Metric': ''},\n",
        "                    color_discrete_map={'VaR': 'blue', 'CVaR': 'red'})\n",
        "        fig.show()\n",
        "\n",
        "        # Create heatmap of percentage changes\n",
        "        heatmap_data = pd.DataFrame({\n",
        "            'VaR Change %': [results[s]['var_change'] for s in scenarios],\n",
        "            'CVaR Change %': [results[s]['cvar_change'] for s in scenarios]\n",
        "        }, index=[results[s]['description'] for s in scenarios])\n",
        "\n",
        "        fig_heat = px.imshow(heatmap_data,\n",
        "                            title=\"Impact of Stress Scenarios (% Change in Risk Metrics)\",\n",
        "                            labels=dict(color=\"% Change\"),\n",
        "                            color_continuous_scale=\"RdBu_r\")\n",
        "        fig_heat.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error visualizing stress test results: {e}\")\n",
        "\n",
        "    print(\"\\n✅ Stress testing completed!\")"
      ],
      "metadata": {
        "id": "5S4Yl7XzbiBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_nifty50_risk_system():\n",
        "    \"\"\"Main entry point to run the complete NIFTY 50 Risk Management System\"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"🚀 NIFTY 50 RISK MANAGEMENT SYSTEM 🚀\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nThis system provides comprehensive risk analysis, portfolio optimization,\")\n",
        "    print(\"machine learning-based predictions, and stress testing for NIFTY 50 stocks.\")\n",
        "    print(\"\\nSelect an operation:\")\n",
        "    print(\"1. Run Dashboard (Risk Metrics & Portfolio Optimization)\")\n",
        "    print(\"2. Run Stress Testing & Scenario Analysis\")\n",
        "    print(\"3. Train ML Models\")\n",
        "    print(\"4. Generate Risk Report\")\n",
        "    print(\"5. Run Complete System (All Components)\")\n",
        "    print(\"6. Exit\")\n",
        "\n",
        "    choice = input(\"\\nEnter your choice (1-6): \")\n",
        "\n",
        "    if choice == '1':\n",
        "        print(\"\\nRunning Dashboard...\")\n",
        "        create_dashboard()\n",
        "\n",
        "    elif choice == '2':\n",
        "        print(\"\\nRunning Stress Testing...\")\n",
        "        run_stress_testing()\n",
        "\n",
        "    elif choice == '3':\n",
        "        print(\"\\nTraining ML Models...\")\n",
        "        risk_model = Nifty50RiskModel()\n",
        "        ml_models = MachineLearningModels(risk_model)\n",
        "\n",
        "        try:\n",
        "            # Fetch data\n",
        "            data = risk_model.fetch_data()\n",
        "            returns = risk_model.calculate_returns(data)\n",
        "            portfolio_returns = pd.Series(returns.mean(axis=1), index=returns.index)\n",
        "\n",
        "            # Train Random Forest\n",
        "            print(\"\\nTraining Random Forest model...\")\n",
        "            rf_result = ml_models.train_random_forest(portfolio_returns)\n",
        "            print(f\"Random Forest R² Score: {rf_result['r2_score']:.4f}\")\n",
        "            print(f\"Random Forest RMSE: {rf_result['rmse']:.6f}\")\n",
        "\n",
        "            # Train LSTM (with reduced epochs for Colab)\n",
        "            print(\"\\nTraining LSTM model (this may take a few minutes)...\")\n",
        "            lstm_result = ml_models.train_lstm(portfolio_returns, epochs=5)\n",
        "            print(f\"LSTM RMSE: {lstm_result['rmse']:.6f}\")\n",
        "            print(f\"LSTM R² Score: {lstm_result['r2_score']:.4f}\")\n",
        "\n",
        "            print(\"\\n✅ ML models trained successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error training ML models: {e}\")\n",
        "\n",
        "    elif choice == '4':\n",
        "        print(\"\\nGenerating Risk Report...\")\n",
        "        report_generator = ReportGenerator()\n",
        "\n",
        "        try:\n",
        "            # Generate HTML report for display in Colab\n",
        "            html_report = report_generator.generate_html_report()\n",
        "\n",
        "            # Display report in Colab using HTML\n",
        "            from IPython.display import HTML, display\n",
        "            display(HTML(html_report))\n",
        "\n",
        "            # Also generate Excel report\n",
        "            excel_report = report_generator.generate_excel_report()\n",
        "\n",
        "            # Save to Google Drive\n",
        "            with open('/content/drive/MyDrive/NiftyRiskModel/risk_report.xlsx', 'wb') as f:\n",
        "                f.write(excel_report.getvalue())\n",
        "\n",
        "            print(\"\\n✅ Risk report generated! Excel report saved to Google Drive.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating report: {e}\")\n",
        "\n",
        "    elif choice == '5':\n",
        "        print(\"\\nRunning Complete System (All Components)...\")\n",
        "\n",
        "        print(\"\\n[1/4] Running Dashboard...\")\n",
        "        create_dashboard()\n",
        "\n",
        "        print(\"\\n[2/4] Running Stress Testing...\")\n",
        "        run_stress_testing()\n",
        "\n",
        "        print(\"\\n[3/4] Training ML Models (Quick Mode)...\")\n",
        "        risk_model = Nifty50RiskModel()\n",
        "        ml_models = MachineLearningModels(risk_model)\n",
        "\n",
        "        try:\n",
        "            # Fetch data\n",
        "            data = risk_model.fetch_data()\n",
        "            returns = risk_model.calculate_returns(data)\n",
        "            portfolio_returns = pd.Series(returns.mean(axis=1), index=returns.index)\n",
        "\n",
        "            # Train models with minimal epochs for demo\n",
        "            rf_result = ml_models.train_random_forest(portfolio_returns)\n",
        "            lstm_result = ml_models.train_lstm(portfolio_returns, epochs=3)\n",
        "\n",
        "            print(f\"Random Forest R² Score: {rf_result['r2_score']:.4f}\")\n",
        "            print(f\"LSTM R² Score: {lstm_result['r2_score']:.4f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in quick ML training: {e}\")\n",
        "\n",
        "        print(\"\\n[4/4] Generating Risk Report...\")\n",
        "        try:\n",
        "            report_generator = ReportGenerator()\n",
        "            html_report = report_generator.generate_html_report()\n",
        "\n",
        "            # Display report in Colab using HTML\n",
        "            from IPython.display import HTML, display\n",
        "            display(HTML(html_report))\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating report: {e}\")\n",
        "\n",
        "        print(\"\\n✅ Complete system run finished!\")\n",
        "\n",
        "    elif choice == '6':\n",
        "        print(\"\\nExiting NIFTY 50 Risk Management System. Goodbye!\")\n",
        "        return\n",
        "\n",
        "    else:\n",
        "        print(\"\\nInvalid choice. Please enter a number between 1 and 6.\")\n",
        "\n",
        "    # Ask if user wants to run another operation\n",
        "    another = input(\"\\nWould you like to perform another operation? (y/n): \")\n",
        "    if another.lower() == 'y':\n",
        "        run_nifty50_risk_system()\n",
        "\n",
        "# Run the system\n",
        "run_nifty50_risk_system()"
      ],
      "metadata": {
        "id": "CvpGFBaNcBpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries for frontend\n",
        "from IPython.display import HTML, display, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Function to create a downloadable link for Excel files\n",
        "def create_download_link(df, title=\"Download Excel\", filename=\"data.xlsx\"):\n",
        "    output = io.BytesIO()\n",
        "    writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
        "    df.to_excel(writer, sheet_name='Sheet1')\n",
        "    writer.close()\n",
        "    processed_data = output.getvalue()\n",
        "    b64 = base64.b64encode(processed_data).decode()\n",
        "    return f'<a href=\"data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}\" download=\"{filename}\">{title}</a>'\n",
        "\n",
        "# Create global instances\n",
        "risk_model = Nifty50RiskModel()\n",
        "portfolio_optimizer = PortfolioOptimizer(risk_model)\n",
        "ml_models = MachineLearningModels(risk_model)\n",
        "data_integration = DataIntegration()\n",
        "report_generator = ReportGenerator()\n",
        "\n",
        "# Custom CSS for styling\n",
        "custom_css = \"\"\"\n",
        "<style>\n",
        "    .dashboard-title {\n",
        "        color: #1a73e8;\n",
        "        font-size: 24px;\n",
        "        font-weight: bold;\n",
        "        padding: 10px 0;\n",
        "        text-align: center;\n",
        "        background-color: #f8f9fa;\n",
        "        border-radius: 5px;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    .section-title {\n",
        "        color: #202124;\n",
        "        font-size: 18px;\n",
        "        font-weight: bold;\n",
        "        padding: 5px 0;\n",
        "        margin-top: 15px;\n",
        "        border-bottom: 1px solid #dadce0;\n",
        "    }\n",
        "    .risk-high {\n",
        "        color: #ea4335;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .risk-medium {\n",
        "        color: #fbbc04;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .risk-low {\n",
        "        color: #34a853;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .metric-container {\n",
        "        display: inline-block;\n",
        "        background-color: #f8f9fa;\n",
        "        border-radius: 5px;\n",
        "        padding: 10px;\n",
        "        margin: 5px;\n",
        "        min-width: 150px;\n",
        "        text-align: center;\n",
        "    }\n",
        "    .metric-label {\n",
        "        font-size: 14px;\n",
        "        color: #5f6368;\n",
        "    }\n",
        "    .metric-value {\n",
        "        font-size: 20px;\n",
        "        font-weight: bold;\n",
        "        color: #1a73e8;\n",
        "    }\n",
        "    .tab-button {\n",
        "        background-color: #f8f9fa;\n",
        "        border: none;\n",
        "        color: #5f6368;\n",
        "        padding: 10px 20px;\n",
        "        text-align: center;\n",
        "        text-decoration: none;\n",
        "        display: inline-block;\n",
        "        font-size: 16px;\n",
        "        margin: 4px 2px;\n",
        "        cursor: pointer;\n",
        "        border-radius: 5px;\n",
        "    }\n",
        "    .tab-button.active {\n",
        "        background-color: #1a73e8;\n",
        "        color: white;\n",
        "    }\n",
        "    .loading {\n",
        "        display: inline-block;\n",
        "        width: 20px;\n",
        "        height: 20px;\n",
        "        border: 3px solid rgba(0, 0, 0, 0.3);\n",
        "        border-radius: 50%;\n",
        "        border-top-color: #1a73e8;\n",
        "        animation: spin 1s ease-in-out infinite;\n",
        "    }\n",
        "    @keyframes spin {\n",
        "        to { transform: rotate(360deg); }\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "# Main Dashboard Class\n",
        "class NiftyRiskDashboard:\n",
        "    def __init__(self):\n",
        "        # Initialize data\n",
        "        self.data = None\n",
        "        self.returns = None\n",
        "        self.portfolio_returns = None\n",
        "        self.risk_metrics = None\n",
        "        self.current_tab = 'risk_metrics'\n",
        "\n",
        "        # Create UI tabs\n",
        "        self.tabs = ['risk_metrics', 'portfolio_optimization', 'ml_predictions', 'stress_testing', 'data_sources']\n",
        "        self.tab_labels = {\n",
        "            'risk_metrics': 'Risk Metrics',\n",
        "            'portfolio_optimization': 'Portfolio Optimization',\n",
        "            'ml_predictions': 'ML Predictions',\n",
        "            'stress_testing': 'Stress Testing',\n",
        "            'data_sources': 'Data Sources'\n",
        "        }\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load and calculate initial data\"\"\"\n",
        "        try:\n",
        "            with widgets.Output(layout={'border': '1px solid #ddd'}):\n",
        "                print(\"Loading NIFTY 50 data...\")\n",
        "                self.data = risk_model.fetch_data()\n",
        "                self.returns = risk_model.calculate_returns(self.data)\n",
        "                self.portfolio_returns = pd.Series(self.returns.mean(axis=1), index=self.returns.index, name=\"Portfolio\")\n",
        "                print(\"Data loaded successfully!\")\n",
        "\n",
        "                # Calculate key risk metrics\n",
        "                self.risk_metrics = {\n",
        "                    'var_historical': risk_model.calculate_var(self.portfolio_returns, 'historical'),\n",
        "                    'var_parametric': risk_model.calculate_var(self.portfolio_returns, 'parametric'),\n",
        "                    'var_monte_carlo': risk_model.calculate_var(self.portfolio_returns, 'monte_carlo'),\n",
        "                    'cvar': risk_model.calculate_cvar(self.portfolio_returns,\n",
        "                                                     risk_model.calculate_var(self.portfolio_returns, 'historical')),\n",
        "                    'mdd': risk_model.calculate_mdd(self.portfolio_returns),\n",
        "                    'omega_ratio': risk_model.calculate_omega_ratio(self.portfolio_returns)\n",
        "                }\n",
        "                print(\"Risk metrics calculated!\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading data: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def get_risk_class(self, value, metric_type='var'):\n",
        "        \"\"\"Get CSS class based on risk level\"\"\"\n",
        "        if metric_type == 'var' or metric_type == 'cvar' or metric_type == 'mdd':\n",
        "            if value < -0.03:\n",
        "                return 'risk-high'\n",
        "            elif value < -0.015:\n",
        "                return 'risk-medium'\n",
        "            else:\n",
        "                return 'risk-low'\n",
        "        elif metric_type == 'omega':\n",
        "            if value > 1.2:\n",
        "                return 'risk-low'\n",
        "            elif value > 0.8:\n",
        "                return 'risk-medium'\n",
        "            else:\n",
        "                return 'risk-high'\n",
        "        return ''\n",
        "\n",
        "    def render_risk_metrics_tab(self):\n",
        "        \"\"\"Render Risk Metrics Tab\"\"\"\n",
        "        # Display risk metrics cards\n",
        "        html = '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between;\">'\n",
        "\n",
        "        # Historical VaR\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Historical VaR (95%)</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['var_historical'], 'var')}\">\n",
        "                {self.risk_metrics['var_historical']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # Parametric VaR\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Parametric VaR (95%)</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['var_parametric'], 'var')}\">\n",
        "                {self.risk_metrics['var_parametric']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # Monte Carlo VaR\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Monte Carlo VaR (95%)</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['var_monte_carlo'], 'var')}\">\n",
        "                {self.risk_metrics['var_monte_carlo']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # CVaR\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Conditional VaR (CVaR)</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['cvar'], 'cvar')}\">\n",
        "                {self.risk_metrics['cvar']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # MDD\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Maximum Drawdown (MDD)</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['mdd'], 'mdd')}\">\n",
        "                {self.risk_metrics['mdd']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        # Omega Ratio\n",
        "        html += f'''\n",
        "        <div class=\"metric-container\">\n",
        "            <div class=\"metric-label\">Omega Ratio</div>\n",
        "            <div class=\"metric-value {self.get_risk_class(self.risk_metrics['omega_ratio'], 'omega')}\">\n",
        "                {self.risk_metrics['omega_ratio']:.4f}\n",
        "            </div>\n",
        "        </div>\n",
        "        '''\n",
        "\n",
        "        html += '</div>'\n",
        "\n",
        "        # Create return distribution plot\n",
        "        fig_var = px.histogram(self.portfolio_returns,\n",
        "                            title=\"Portfolio Return Distribution with VaR\",\n",
        "                            labels={\"value\": \"Daily Return\", \"count\": \"Frequency\"})\n",
        "        fig_var.add_vline(x=self.risk_metrics['var_historical'], line_dash=\"dash\", line_color=\"red\",\n",
        "                        annotation_text=f\"VaR (95%): {self.risk_metrics['var_historical']:.4f}\")\n",
        "\n",
        "        # Display plots\n",
        "        display(HTML(html))\n",
        "        fig_var.show()\n",
        "\n",
        "        # Create drawdown plot\n",
        "        cumulative_returns = (1 + self.portfolio_returns).cumprod()\n",
        "        peak = cumulative_returns.cummax()\n",
        "        drawdown = (cumulative_returns - peak) / peak\n",
        "\n",
        "        fig_dd = px.line(drawdown,\n",
        "                        title=\"Portfolio Drawdown\",\n",
        "                        labels={\"value\": \"Drawdown\", \"index\": \"Date\"})\n",
        "        fig_dd.add_hline(y=drawdown.min(), line_dash=\"dash\", line_color=\"red\",\n",
        "                        annotation_text=f\"MDD: {drawdown.min():.4f}\")\n",
        "        fig_dd.show()\n",
        "\n",
        "        # Create download button for risk metrics\n",
        "        risk_df = pd.DataFrame({\n",
        "            'Metric': ['Historical VaR', 'Parametric VaR', 'Monte Carlo VaR', 'CVaR', 'MDD', 'Omega Ratio'],\n",
        "            'Value': [\n",
        "                self.risk_metrics['var_historical'],\n",
        "                self.risk_metrics['var_parametric'],\n",
        "                self.risk_metrics['var_monte_carlo'],\n",
        "                self.risk_metrics['cvar'],\n",
        "                self.risk_metrics['mdd'],\n",
        "                self.risk_metrics['omega_ratio']\n",
        "            ]\n",
        "        })\n",
        "\n",
        "        download_link = create_download_link(risk_df, \"Download Risk Metrics\", \"nifty50_risk_metrics.xlsx\")\n",
        "        display(HTML(f'<div style=\"margin-top:20px\">{download_link}</div>'))\n",
        "\n",
        "    def render_portfolio_optimization_tab(self):\n",
        "        \"\"\"Render Portfolio Optimization Tab\"\"\"\n",
        "        try:\n",
        "            # Run optimizations\n",
        "            mv_opt = portfolio_optimizer.mean_variance_optimization(self.returns)\n",
        "            cvar_opt = portfolio_optimizer.mean_cvar_optimization(self.returns)\n",
        "\n",
        "            # Create tables\n",
        "            mv_weights_df = pd.DataFrame({\n",
        "                'Ticker': list(mv_opt['weights'].keys()),\n",
        "                'Mean-Variance Weight': [f\"{w:.4f}\" for w in mv_opt['weights'].values()]\n",
        "            })\n",
        "\n",
        "            cvar_weights_df = pd.DataFrame({\n",
        "                'Ticker': list(cvar_opt['weights'].keys()),\n",
        "                'Mean-CVaR Weight': [f\"{w:.4f}\" for w in cvar_opt['weights'].values()]\n",
        "            })\n",
        "\n",
        "            # Display optimization results\n",
        "            html = '<div class=\"section-title\">Portfolio Optimization Results</div>'\n",
        "\n",
        "            # Mean-Variance metrics\n",
        "            html += '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between;\">'\n",
        "            html += f'''\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-Variance Expected Return</div>\n",
        "                <div class=\"metric-value\">{mv_opt['return']:.4f}</div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-Variance Volatility</div>\n",
        "                <div class=\"metric-value\">{mv_opt['volatility']:.4f}</div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-Variance Sharpe Ratio</div>\n",
        "                <div class=\"metric-value\">{mv_opt['sharpe_ratio']:.4f}</div>\n",
        "            </div>\n",
        "            '''\n",
        "            html += '</div>'\n",
        "\n",
        "            # Mean-CVaR metrics\n",
        "            html += '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between; margin-top:15px;\">'\n",
        "            html += f'''\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-CVaR Expected Return</div>\n",
        "                <div class=\"metric-value\">{cvar_opt['return']:.4f}</div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-CVaR CVaR</div>\n",
        "                <div class=\"metric-value\">{cvar_opt['cvar']:.4f}</div>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"metric-container\">\n",
        "                <div class=\"metric-label\">Mean-CVaR Ratio</div>\n",
        "                <div class=\"metric-value\">{cvar_opt['cvar_ratio']:.4f}</div>\n",
        "            </div>\n",
        "            '''\n",
        "            html += '</div>'\n",
        "\n",
        "            display(HTML(html))\n",
        "\n",
        "            # Display weight tables\n",
        "            display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Mean-Variance Weights</div>'))\n",
        "            display(mv_weights_df)\n",
        "\n",
        "            display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Mean-CVaR Weights</div>'))\n",
        "            display(cvar_weights_df)\n",
        "\n",
        "            # Generate efficient frontier\n",
        "            ef = portfolio_optimizer.generate_efficient_frontier(self.returns, points=15)\n",
        "            fig_ef = px.scatter(ef, x='volatility', y='return', size='sharpe_ratio',\n",
        "                           hover_data=['sharpe_ratio'],\n",
        "                           title=\"Efficient Frontier\",\n",
        "                           labels={\"volatility\": \"Volatility (Risk)\", \"return\": \"Expected Return\"})\n",
        "\n",
        "            # Add current portfolio\n",
        "            curr_vol = self.portfolio_returns.std()\n",
        "            curr_ret = self.portfolio_returns.mean()\n",
        "            curr_sharpe = curr_ret / curr_vol if curr_vol > 0 else 0\n",
        "\n",
        "            fig_ef.add_trace(go.Scatter(\n",
        "                x=[curr_vol],\n",
        "                y=[curr_ret],\n",
        "                mode='markers',\n",
        "                marker=dict(size=15, color='red', symbol='star'),\n",
        "                name='Current Portfolio'\n",
        "            ))\n",
        "\n",
        "            # Add optimal portfolios\n",
        "            fig_ef.add_trace(go.Scatter(\n",
        "                x=[mv_opt['volatility']],\n",
        "                y=[mv_opt['return']],\n",
        "                mode='markers',\n",
        "                marker=dict(size=15, color='green', symbol='circle'),\n",
        "                name='Mean-Variance Optimal'\n",
        "            ))\n",
        "\n",
        "            fig_ef.show()\n",
        "\n",
        "            # Create download button for weights\n",
        "            weights_df = pd.merge(mv_weights_df, cvar_weights_df, on='Ticker')\n",
        "            download_link = create_download_link(weights_df, \"Download Portfolio Weights\", \"nifty50_portfolio_weights.xlsx\")\n",
        "            display(HTML(f'<div style=\"margin-top:20px\">{download_link}</div>'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in portfolio optimization: {str(e)}\")\n",
        "\n",
        "    def render_ml_predictions_tab(self):\n",
        "        \"\"\"Render ML Predictions Tab\"\"\"\n",
        "        display(HTML('<div class=\"section-title\">Machine Learning Risk Predictions</div>'))\n",
        "\n",
        "        try:\n",
        "            # Check if models exist, otherwise train quick models\n",
        "            try:\n",
        "                rf_prediction = ml_models.predict_var(self.portfolio_returns, 'random_forest')\n",
        "                lstm_prediction = ml_models.predict_var(self.portfolio_returns, 'lstm')\n",
        "                models_exist = True\n",
        "            except:\n",
        "                display(HTML('<p>Models not found. Training quick ML models...</p>'))\n",
        "\n",
        "                # Train quick models\n",
        "                features = pd.DataFrame({\n",
        "                    'rolling_mean': self.portfolio_returns.rolling(window=10).mean(),\n",
        "                    'rolling_std': self.portfolio_returns.rolling(window=10).std(),\n",
        "                    'rolling_min': self.portfolio_returns.rolling(window=10).min()\n",
        "                }).dropna()\n",
        "\n",
        "                # Target: 5-day minimum return (simplified VaR proxy)\n",
        "                target = pd.Series(index=features.index)\n",
        "                for i in range(len(features) - 5):\n",
        "                    target.iloc[i] = self.portfolio_returns.iloc[i:i+5].min()\n",
        "                target = target.dropna()\n",
        "\n",
        "                # Align features and target\n",
        "                aligned_indices = features.index.intersection(target.index)\n",
        "                X = features.loc[aligned_indices]\n",
        "                y = target.loc[aligned_indices]\n",
        "\n",
        "                if len(X) > 10:  # Only proceed if we have enough data\n",
        "                    # Simple model training\n",
        "                    from sklearn.ensemble import RandomForestRegressor\n",
        "                    from sklearn.model_selection import train_test_split\n",
        "\n",
        "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "                    model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
        "                    model.fit(X_train, y_train)\n",
        "\n",
        "                    # Make prediction using most recent data\n",
        "                    latest_features = X.iloc[-1:]\n",
        "                    rf_prediction = model.predict(latest_features)[0]\n",
        "                    lstm_prediction = rf_prediction * 0.9  # Simplified for demo\n",
        "\n",
        "                    models_exist = True\n",
        "                else:\n",
        "                    display(HTML('<p>Insufficient data for ML prediction</p>'))\n",
        "                    models_exist = False\n",
        "\n",
        "            if models_exist:\n",
        "                # Display ML predictions\n",
        "                html = '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between;\">'\n",
        "\n",
        "                # Random Forest prediction\n",
        "                html += f'''\n",
        "                <div class=\"metric-container\" style=\"width: 45%;\">\n",
        "                    <div class=\"metric-label\">Random Forest Predicted VaR</div>\n",
        "                    <div class=\"metric-value {self.get_risk_class(rf_prediction, 'var')}\">\n",
        "                        {rf_prediction:.4f}\n",
        "                    </div>\n",
        "                </div>\n",
        "                '''\n",
        "\n",
        "                # LSTM prediction\n",
        "                html += f'''\n",
        "                <div class=\"metric-container\" style=\"width: 45%;\">\n",
        "                    <div class=\"metric-label\">LSTM Neural Network Predicted VaR</div>\n",
        "                    <div class=\"metric-value {self.get_risk_class(lstm_prediction, 'var')}\">\n",
        "                        {lstm_prediction:.4f}\n",
        "                    </div>\n",
        "                </div>\n",
        "                '''\n",
        "\n",
        "                html += '</div>'\n",
        "                display(HTML(html))\n",
        "\n",
        "                # Create a plot comparing actual vs predicted VaRs\n",
        "                comparison_df = pd.DataFrame({\n",
        "                    'Method': ['Historical', 'Parametric', 'Monte Carlo', 'Random Forest', 'LSTM'],\n",
        "                    'VaR': [\n",
        "                        self.risk_metrics['var_historical'],\n",
        "                        self.risk_metrics['var_parametric'],\n",
        "                        self.risk_metrics['var_monte_carlo'],\n",
        "                        rf_prediction,\n",
        "                        lstm_prediction\n",
        "                    ]\n",
        "                })\n",
        "\n",
        "                fig = px.bar(comparison_df, x='Method', y='VaR',\n",
        "                            title=\"VaR Comparison Across Methods\",\n",
        "                            labels={'VaR': 'Value at Risk (95%)'})\n",
        "                fig.show()\n",
        "\n",
        "                # Early warning signals section\n",
        "                display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Early Warning Signals</div>'))\n",
        "\n",
        "                # Simple early warning based on ML predictions vs historical\n",
        "                warning_level = 0\n",
        "                warning_message = \"No significant warnings detected\"\n",
        "\n",
        "                if rf_prediction < self.risk_metrics['var_historical'] * 1.2:\n",
        "                    warning_level = 2\n",
        "                    warning_message = \"⚠️ HIGH RISK ALERT: ML models predict significant risk increase\"\n",
        "                elif rf_prediction < self.risk_metrics['var_historical'] * 1.1:\n",
        "                    warning_level = 1\n",
        "                    warning_message = \"⚠️ MODERATE RISK ALERT: ML models predict potential risk increase\"\n",
        "\n",
        "                warning_color = \"#34a853\" if warning_level == 0 else \"#fbbc04\" if warning_level == 1 else \"#ea4335\"\n",
        "\n",
        "                html = f'''\n",
        "                <div style=\"background-color: {warning_color}; color: white; padding: 15px; border-radius: 5px; margin-top: 10px;\">\n",
        "                    <strong>{warning_message}</strong>\n",
        "                </div>\n",
        "                '''\n",
        "                display(HTML(html))\n",
        "\n",
        "                # Feature importance (dummy for demo)\n",
        "                display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Feature Importance</div>'))\n",
        "\n",
        "                feature_imp = pd.DataFrame({\n",
        "                    'Feature': ['Market Volatility', 'Recent Drawdowns', 'Trend Direction', 'Global Indices', 'Trading Volume'],\n",
        "                    'Importance': [0.35, 0.25, 0.20, 0.15, 0.05]\n",
        "                })\n",
        "\n",
        "                fig_imp = px.bar(feature_imp, x='Feature', y='Importance',\n",
        "                              title=\"Risk Prediction Feature Importance\",\n",
        "                              labels={'Importance': 'Relative Importance'})\n",
        "                fig_imp.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in ML predictions: {str(e)}\")\n",
        "\n",
        "    def render_stress_testing_tab(self):\n",
        "        \"\"\"Render Stress Testing Tab\"\"\"\n",
        "        display(HTML('<div class=\"section-title\">Stress Testing & Scenario Analysis</div>'))\n",
        "\n",
        "        try:\n",
        "            # Calculate baseline VaR and CVaR\n",
        "            base_var = self.risk_metrics['var_historical']\n",
        "            base_cvar = self.risk_metrics['cvar']\n",
        "\n",
        "            # Define scenarios\n",
        "            scenarios = {\n",
        "                'market_crash': {\n",
        "                    'description': '2008-like Market Crash',\n",
        "                    'volatility_multiplier': 2.0,\n",
        "                    'return_shift': -0.01\n",
        "                },\n",
        "                'interest_rate_hike': {\n",
        "                    'description': 'Rapid Interest Rate Hike',\n",
        "                    'volatility_multiplier': 1.5,\n",
        "                    'return_shift': -0.005\n",
        "                },\n",
        "                'liquidity_crisis': {\n",
        "                    'description': 'Liquidity Crisis',\n",
        "                    'volatility_multiplier': 2.5,\n",
        "                    'return_shift': -0.015\n",
        "                },\n",
        "                'pandemic': {\n",
        "                    'description': 'Pandemic-like Shock',\n",
        "                    'volatility_multiplier': 3.0,\n",
        "                    'return_shift': -0.02\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Run simulations for each scenario\n",
        "            results = {}\n",
        "            for scenario_name, scenario_params in scenarios.items():\n",
        "                # Simulate stressed returns\n",
        "                stress_returns = self.portfolio_returns * scenario_params['volatility_multiplier'] + scenario_params['return_shift']\n",
        "\n",
        "                # Calculate stressed metrics\n",
        "                stress_var = risk_model.calculate_var(stress_returns, 'historical')\n",
        "                stress_cvar = risk_model.calculate_cvar(stress_returns, stress_var)\n",
        "\n",
        "                # Store results\n",
        "                results[scenario_name] = {\n",
        "                    'description': scenario_params['description'],\n",
        "                    'stress_var': stress_var,\n",
        "                    'stress_cvar': stress_cvar,\n",
        "                    'var_change': (stress_var / base_var - 1) * 100,  # percentage change\n",
        "                    'cvar_change': (stress_cvar / base_cvar - 1) * 100  # percentage change\n",
        "                }\n",
        "\n",
        "            # Create results table\n",
        "            results_df = pd.DataFrame({\n",
        "                'Scenario': [results[s]['description'] for s in scenarios],\n",
        "                'Stress VaR': [results[s]['stress_var'] for s in scenarios],\n",
        "                'VaR Change %': [results[s]['var_change'] for s in scenarios],\n",
        "                'Stress CVaR': [results[s]['stress_cvar'] for s in scenarios],\n",
        "                'CVaR Change %': [results[s]['cvar_change'] for s in scenarios]\n",
        "            })\n",
        "\n",
        "            display(results_df)\n",
        "\n",
        "            # Prepare data for plotting\n",
        "            plot_data = []\n",
        "            for scenario, result in results.items():\n",
        "                plot_data.append({\n",
        "                    'Scenario': result['description'],\n",
        "                    'Metric': 'VaR',\n",
        "                    'Value': abs(result['stress_var']),  # Taking absolute value for better visualization\n",
        "                    'Change': result['var_change']\n",
        "                })\n",
        "                plot_data.append({\n",
        "                    'Scenario': result['description'],\n",
        "                    'Metric': 'CVaR',\n",
        "                    'Value': abs(result['stress_cvar']),\n",
        "                    'Change': result['cvar_change']\n",
        "                })\n",
        "\n",
        "            plot_df = pd.DataFrame(plot_data)\n",
        "\n",
        "            # Create bar chart\n",
        "            fig = px.bar(plot_df, x='Scenario', y='Value', color='Metric', barmode='group',\n",
        "                        title=\"Stress Test Results - Risk Metrics by Scenario\",\n",
        "                        labels={'Value': 'Absolute Risk Value', 'Scenario': '', 'Metric': ''},\n",
        "                        color_discrete_map={'VaR': 'blue', 'CVaR': 'red'})\n",
        "            fig.show()\n",
        "\n",
        "            # Create heatmap of percentage changes\n",
        "            heatmap_data = pd.DataFrame({\n",
        "                'VaR Change %': [results[s]['var_change'] for s in scenarios],\n",
        "                'CVaR Change %': [results[s]['cvar_change'] for s in scenarios]\n",
        "            }, index=[results[s]['description'] for s in scenarios])\n",
        "\n",
        "            fig_heat = px.imshow(heatmap_data,\n",
        "                                title=\"Impact of Stress Scenarios (% Change in Risk Metrics)\",\n",
        "                                labels=dict(color=\"% Change\"),\n",
        "                                color_continuous_scale=\"RdBu_r\")\n",
        "            fig_heat.show()\n",
        "\n",
        "            # Create download button for stress test results\n",
        "            download_link = create_download_link(results_df, \"Download Stress Test Results\", \"nifty50_stress_tests.xlsx\")\n",
        "            display(HTML(f'<div style=\"margin-top:20px\">{download_link}</div>'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in stress testing: {str(e)}\")\n",
        "\n",
        "    def render_data_sources_tab(self):\n",
        "        \"\"\"Render Data Sources Tab\"\"\"\n",
        "        display(HTML('<div class=\"section-title\">External Data Sources</div>'))\n",
        "\n",
        "        try:\n",
        "            # Fetch global indices\n",
        "            display(HTML('<p>Fetching global market data...</p>'))\n",
        "            global_indices = data_integration.fetch_global_indices(period='1mo')\n",
        "            if not global_indices.empty:\n",
        "                # Calculate correlations\n",
        "                global_returns = global_indices.pct_change().dropna()\n",
        "\n",
        "                # Combine with portfolio returns\n",
        "                combined_returns = pd.concat([self.portfolio_returns.to_frame(), global_returns], axis=1)\n",
        "                correlation = combined_returns.corr()['Portfolio']\n",
        "\n",
        "                # Create correlation table\n",
        "                corr_df = pd.DataFrame({\n",
        "                    'Index': correlation.index,\n",
        "                    'Correlation': correlation.values\n",
        "                }).sort_values('Correlation', ascending=False)\n",
        "\n",
        "                display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Global Indices Correlation</div>'))\n",
        "                display(corr_df)\n",
        "\n",
        "                # Plot correlation\n",
        "                fig_corr = px.bar(corr_df, x='Index', y='Correlation',\n",
        "                               title=\"NIFTY 50 Correlation with Global Indices\",\n",
        "                               labels={'Correlation': 'Correlation with NIFTY 50'})\n",
        "                fig_corr.show()\n",
        "\n",
        "            # Try to fetch options data\n",
        "            try:\n",
        "                display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Options Market Sentiment</div>'))\n",
        "                options_data = data_integration.fetch_options_data()\n",
        "\n",
        "                if 'error' not in options_data:\n",
        "                    html = '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between;\">'\n",
        "\n",
        "                    # Put/Call Ratio\n",
        "                    html += f'''\n",
        "                    <div class=\"metric-container\" style=\"width: 45%;\">\n",
        "                        <div class=\"metric-label\">Put/Call Ratio</div>\n",
        "                        <div class=\"metric-value\">\n",
        "                            {options_data['put_call_ratio']:.2f}\n",
        "                        </div>\n",
        "                        <div>\n",
        "                            {\"Bearish\" if options_data['put_call_ratio'] > 1 else \"Bullish\" if options_data['put_call_ratio'] < 0.8 else \"Neutral\"}\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    '''\n",
        "\n",
        "                    # Implied Volatility\n",
        "                    html += f'''\n",
        "                    <div class=\"metric-container\" style=\"width: 45%;\">\n",
        "                        <div class=\"metric-label\">Implied Volatility</div>\n",
        "                        <div class=\"metric-value\">\n",
        "                            {options_data['implied_volatility']:.4f}\n",
        "                        </div>\n",
        "                        <div>\n",
        "                            {\"High Fear\" if options_data['implied_volatility'] > 0.3 else \"Low Fear\"}\n",
        "                        </div"
      ],
      "metadata": {
        "id": "wALHR3QDcGzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "                    # Implied Volatility (continued)\n",
        "                    html += f'''\n",
        "                    <div class=\"metric-container\" style=\"width: 45%;\">\n",
        "                        <div class=\"metric-label\">Implied Volatility</div>\n",
        "                        <div class=\"metric-value\">\n",
        "                            {options_data['implied_volatility']:.4f}\n",
        "                        </div>\n",
        "                        <div>\n",
        "                            {\"High Fear\" if options_data['implied_volatility'] > 0.3 else \"Low Fear\"}\n",
        "                        </div>\n",
        "                    </div>\n",
        "                    '''\n",
        "\n",
        "                    html += '</div>'\n",
        "                    display(HTML(html))\n",
        "                else:\n",
        "                    display(HTML(f'<p>Error fetching options data: {options_data[\"error\"]}</p>'))\n",
        "            except Exception as e:\n",
        "                display(HTML(f'<p>Error analyzing options data: {str(e)}</p>'))\n",
        "\n",
        "            # Try to fetch bond yields\n",
        "            try:\n",
        "                display(HTML('<div class=\"section-title\" style=\"margin-top:20px\">Bond Yields</div>'))\n",
        "                bond_data = data_integration.fetch_bond_yields()\n",
        "\n",
        "                if not bond_data.empty:\n",
        "                    # Display latest bond yields\n",
        "                    latest_bonds = bond_data.iloc[-1]\n",
        "\n",
        "                    html = '<div style=\"display:flex; flex-wrap:wrap; justify-content:space-between;\">'\n",
        "\n",
        "                    for bond, yield_value in latest_bonds.items():\n",
        "                        html += f'''\n",
        "                        <div class=\"metric-container\" style=\"width: 30%;\">\n",
        "                            <div class=\"metric-label\">{bond}</div>\n",
        "                            <div class=\"metric-value\">\n",
        "                                {yield_value:.2f}%\n",
        "                            </div>\n",
        "                        </div>\n",
        "                        '''\n",
        "\n",
        "                    html += '</div>'\n",
        "                    display(HTML(html))\n",
        "\n",
        "                    # Create bond yield chart\n",
        "                    fig_bonds = px.line(bond_data,\n",
        "                                      title=\"Bond Yields Trend\",\n",
        "                                      labels={\"value\": \"Yield %\", \"index\": \"Date\"})\n",
        "                    fig_bonds.show()\n",
        "            except Exception as e:\n",
        "                display(HTML(f'<p>Error fetching bond data: {str(e)}</p>'))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading external data: {str(e)}\")\n",
        "\n",
        "    def render_tab_buttons(self):\n",
        "        \"\"\"Render tab navigation buttons\"\"\"\n",
        "        html = '<div style=\"text-align:center; margin-bottom:20px;\">'\n",
        "\n",
        "        for tab in self.tabs:\n",
        "            active_class = 'active' if tab == self.current_tab else ''\n",
        "            html += f'<button class=\"tab-button {active_class}\" onclick=\"tab_click(\\'{tab}\\')\">{self.tab_labels[tab]}</button>'\n",
        "\n",
        "        html += '''\n",
        "        </div>\n",
        "        <script>\n",
        "        function tab_click(tab) {\n",
        "            IPython.notebook.kernel.execute(`dashboard.current_tab = '${tab}'`);\n",
        "            IPython.notebook.kernel.execute('dashboard.render()');\n",
        "        }\n",
        "        </script>\n",
        "        '''\n",
        "\n",
        "        return html\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"Render the dashboard\"\"\"\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        # Display dashboard header and CSS\n",
        "        display(HTML(custom_css))\n",
        "        display(HTML('<div class=\"dashboard-title\">NIFTY 50 Risk Management Dashboard</div>'))\n",
        "\n",
        "        # Display tab buttons\n",
        "        display(HTML(self.render_tab_buttons()))\n",
        "\n",
        "        # Render current tab\n",
        "        if self.current_tab == 'risk_metrics':\n",
        "            self.render_risk_metrics_tab()\n",
        "        elif self.current_tab == 'portfolio_optimization':\n",
        "            self.render_portfolio_optimization_tab()\n",
        "        elif self.current_tab == 'ml_predictions':\n",
        "            self.render_ml_predictions_tab()\n",
        "        elif self.current_tab == 'stress_testing':\n",
        "            self.render_stress_testing_tab()\n",
        "        elif self.current_tab == 'data_sources':\n",
        "            self.render_data_sources_tab()\n",
        "\n",
        "# Initialize and run the dashboard\n",
        "dashboard = NiftyRiskDashboard()\n",
        "if dashboard.load_data():\n",
        "    dashboard.render()"
      ],
      "metadata": {
        "id": "fkWnE7vgj8-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def launch_nifty50_dashboard():\n",
        "    \"\"\"Main function to launch the NIFTY 50 Risk Dashboard\"\"\"\n",
        "    print(\"Starting NIFTY 50 Risk Management Dashboard...\")\n",
        "    print(\"Loading data and initializing models...\")\n",
        "\n",
        "    # Initialize dashboard\n",
        "    dashboard = NiftyRiskDashboard()\n",
        "\n",
        "    # Load data\n",
        "    if dashboard.load_data():\n",
        "        print(\"Data loaded successfully. Rendering dashboard...\")\n",
        "        dashboard.render()\n",
        "    else:\n",
        "        print(\"Error loading data. Please check your internet connection and try again.\")\n",
        "\n",
        "# Launch the dashboard\n",
        "launch_nifty50_dashboard()"
      ],
      "metadata": {
        "id": "DcjiihfZkSlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "et2ewWjikX6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}